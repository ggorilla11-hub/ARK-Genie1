// ============================================
// AgentPage.jsx v25.0 - AIì§€ë‹ˆ ë©”ì¸ í˜ì´ì§€
// ìˆ˜ì • ë‚´ìš©:
// - ğŸ”§ ì´ë¯¸ì§€ ë¶„ì„ API ê²½ë¡œ ìˆ˜ì • (/api/analyze-image)
// - ğŸ”§ ìŒì„± ì¬ìƒ ë¡œì§ ê°•í™” (AudioContext ì•ˆì •í™”)
// - ğŸ”§ ì „í™” ë³µëª…ë³µì°½ ë¡œì§ ë‹¨ìˆœí™”
// - âœ¨ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ìë™ OCR ì•ˆë‚´ ë©”ì‹œì§€
// ============================================

import React, { useState, useRef, useEffect } from 'react';
import './AgentPage.css';

const RENDER_SERVER = 'https://ark-genie-server.onrender.com';
const WS_SERVER = 'wss://ark-genie-server.onrender.com';

function AgentPage() {
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [isVoiceMode, setIsVoiceMode] = useState(false);
  const [status, setStatus] = useState('ëŒ€ê¸°ì¤‘');
  const [currentCall, setCurrentCall] = useState(null);
  const [callDuration, setCallDuration] = useState(0);
  const [pendingCall, setPendingCall] = useState(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [showFileMenu, setShowFileMenu] = useState(false);
  const [analysisContextList, setAnalysisContextList] = useState([]);
  
  // ì†Œí†µ UI ìƒíƒœ (ì¹´í†¡/ë¬¸ì/ì´ë©”ì¼/íŒ©ìŠ¤)
  const [pendingComm, setPendingComm] = useState(null);
  const [showCommOverlay, setShowCommOverlay] = useState(false);
  const [commType, setCommType] = useState(null);
  const [commTarget, setCommTarget] = useState(null);
  const [commStatus, setCommStatus] = useState('ready');
  
  const chatAreaRef = useRef(null);
  const wsRef = useRef(null);
  const audioContextRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const processorRef = useRef(null);
  const callTimerRef = useRef(null);
  const audioQueueRef = useRef([]);
  const isPlayingRef = useRef(false);
  const isConnectedRef = useRef(false);
  const lastCallInfoRef = useRef(null);
  const muteServerAudioRef = useRef(false);
  const cameraInputRef = useRef(null);
  const imageInputRef = useRef(null);
  const fileInputRef = useRef(null);
  const messagesEndRef = useRef(null);
  
  // ğŸ”§ v25: ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜ (ì•ˆì •í™”)
  const initAudioContext = async () => {
    try {
      if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        console.log('ğŸ”Š AudioContext ìƒì„±ë¨');
      }
      
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
        console.log('ğŸ”Š AudioContext resumed');
      }
      
      return true;
    } catch (e) {
      console.error('AudioContext ì´ˆê¸°í™” ì‹¤íŒ¨:', e);
      return false;
    }
  };
  
  useEffect(() => {
    const scrollToBottom = () => {
      if (messagesEndRef.current) {
        messagesEndRef.current.scrollIntoView({ behavior: 'smooth' });
      }
    };
    scrollToBottom();
    const timer1 = setTimeout(scrollToBottom, 100);
    const timer2 = setTimeout(scrollToBottom, 300);
    return () => {
      clearTimeout(timer1);
      clearTimeout(timer2);
    };
  }, [messages]);

  useEffect(() => {
    return () => {
      cleanupVoiceMode();
      if (callTimerRef.current) clearInterval(callTimerRef.current);
    };
  }, []);

  useEffect(() => {
    if (!currentCall?.callSid) return;
    
    const pollStatus = async () => {
      try {
        const response = await fetch(`${RENDER_SERVER}/api/call-status/${currentCall.callSid}`);
        const data = await response.json();
        
        if (data.status === 'completed' || data.status === 'failed' || data.status === 'busy' || data.status === 'no-answer') {
          if (callTimerRef.current) {
            clearInterval(callTimerRef.current);
            callTimerRef.current = null;
          }
          const name = currentCall?.name || 'ê³ ê°';
          const duration = formatDuration(callDuration);
          setCurrentCall(null);
          setCallDuration(0);
          setStatus('ëŒ€ê¸°ì¤‘');
          addMessage(`ğŸ“´ ${name}ë‹˜ í†µí™” ì¢…ë£Œ (${duration})`, false);
        }
      } catch (e) {
        console.error('í†µí™” ìƒíƒœ ì¡°íšŒ ì—ëŸ¬:', e);
      }
    };
    
    const intervalId = setInterval(pollStatus, 3000);
    return () => clearInterval(intervalId);
  }, [currentCall, callDuration]);

  // ì†Œí†µ ëª…ë ¹ ê°ì§€ (ì¹´í†¡/ë¬¸ì/ì´ë©”ì¼/íŒ©ìŠ¤)
  const checkCommCommand = (text) => {
    let type = null;
    if (text.includes('ì¹´í†¡') || text.includes('ì¹´ì¹´ì˜¤')) type = 'kakao';
    else if (text.includes('ë¬¸ì')) type = 'sms';
    else if (text.includes('ì´ë©”ì¼') || text.includes('ë©”ì¼')) type = 'email';
    else if (text.includes('íŒ©ìŠ¤')) type = 'fax';
    
    if (!type) return null;
    
    let name = 'ê³ ê°';
    const nameMatch = text.match(/([ê°€-í£]{2,4})/g);
    if (nameMatch) {
      const excludeWords = ['ì¹´í†¡', 'ì¹´ì¹´ì˜¤', 'ë¬¸ì', 'ì´ë©”ì¼', 'ë©”ì¼', 'íŒ©ìŠ¤', 'ë³´ë‚´', 'ì „ì†¡', 'í•´ì¤˜', 'í•´ì£¼ì„¸ìš”', 'ë¶€íƒ', 'ê³ ê°'];
      for (const n of nameMatch) {
        if (!excludeWords.includes(n)) {
          name = n;
          break;
        }
      }
    }
    
    const phoneMatch = text.match(/\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}/);
    const phone = phoneMatch ? phoneMatch[0] : '010-0000-0000';
    
    return { type, name, phone };
  };

  const getCommTypeInfo = (type) => {
    const info = {
      kakao: { icon: 'ğŸ’¬', label: 'ì¹´ì¹´ì˜¤í†¡', color: '#FEE500', textColor: '#191919' },
      sms: { icon: 'ğŸ“±', label: 'ë¬¸ì', color: '#3B82F6', textColor: '#fff' },
      email: { icon: 'ğŸ“§', label: 'ì´ë©”ì¼', color: '#EC4899', textColor: '#fff' },
      fax: { icon: 'ğŸ“ ', label: 'íŒ©ìŠ¤', color: '#8B5CF6', textColor: '#fff' }
    };
    return info[type] || info.kakao;
  };

  const openCommOverlay = (type, target) => {
    setCommType(type);
    setCommTarget(target);
    setCommStatus('ready');
    setShowCommOverlay(true);
  };

  const closeCommOverlay = () => {
    setShowCommOverlay(false);
    setCommType(null);
    setCommTarget(null);
    setCommStatus('ready');
  };

  const executeComm = async () => {
    if (!commType || !commTarget) return;
    
    setCommStatus('sending');
    await new Promise(resolve => setTimeout(resolve, 2000));
    setCommStatus('sent');
    
    const typeLabels = { kakao: 'ì¹´ì¹´ì˜¤í†¡', sms: 'ë¬¸ì', email: 'ì´ë©”ì¼', fax: 'íŒ©ìŠ¤' };
    
    await new Promise(resolve => setTimeout(resolve, 1500));
    closeCommOverlay();
    
    addMessage(`âœ… ${commTarget.name}ë‹˜ê»˜ ${typeLabels[commType]}ì„ ë°œì†¡í–ˆìŠµë‹ˆë‹¤.`, false);
  };

  const handleCommApprove = () => {
    if (!pendingComm) return;
    const commInfo = pendingComm;
    setPendingComm(null);
    openCommOverlay(commInfo.type, { name: commInfo.name, phone: commInfo.phone });
    setTimeout(() => executeComm(), 500);
  };

  const handleCommCancel = () => {
    setPendingComm(null);
    addMessage('ë„¤, ë°œì†¡ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.', false);
  };

  const addMessage = (text, isUser, imageData = null) => {
    setMessages(prev => [...prev, {
      id: Date.now() + Math.random(),
      text,
      isUser,
      imageData,
      time: new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
    }]);
  };

  const clearAnalysisContext = () => {
    setAnalysisContextList([]);
    addMessage('ğŸ—‘ï¸ ë¶„ì„ ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.', false);
  };

  // ğŸ”§ v25: íŒŒì¼ ë¶„ì„ - ì´ë¯¸ì§€ì™€ ë¬¸ì„œ ë¶„ë¦¬
  const handleFileSelect = async (event) => {
    const files = Array.from(event.target.files);
    if (!files || files.length === 0) return;
    
    // ğŸ”§ v25: ìŒì„± ëª¨ë“œ ì¤‘ì´ë©´ AudioContext ë¨¼ì € ì´ˆê¸°í™”
    await initAudioContext();
    
    for (const file of files) {
      const isImage = file.type.startsWith('image/');
      const isPDF = file.type === 'application/pdf' || file.name.endsWith('.pdf');
      
      if (file.size > 20 * 1024 * 1024) {
        addMessage(`âš ï¸ íŒŒì¼ í¬ê¸° ì´ˆê³¼ (20MB ì œí•œ): ${file.name}`, false);
        continue;
      }
      
      try {
        const base64 = await fileToBase64(file);
        const fileName = file.name;
        const fileCount = analysisContextList.length + 1;
        
        // ì—…ë¡œë“œ ë©”ì‹œì§€
        if (isImage) {
          addMessage(`ğŸ“ [${fileCount}ë²ˆì§¸] ì´ë¯¸ì§€ ì—…ë¡œë“œ: ${fileName}`, true, base64);
        } else {
          addMessage(`ğŸ“ [${fileCount}ë²ˆì§¸] íŒŒì¼ ì—…ë¡œë“œ: ${fileName}`, true, null);
        }
        
        setIsAnalyzing(true);
        setStatus(`ğŸ” ë¶„ì„ì¤‘...`);
        
        // ğŸ”§ v25: ì´ë¯¸ì§€ vs ë¬¸ì„œ ë¶„ê¸°
        let analysis;
        if (isImage) {
          // ì´ë¯¸ì§€ëŠ” /api/analyze-imageë¡œ (GPT-4o Vision)
          analysis = await analyzeImage(base64, fileName);
        } else {
          // PDF/ë¬¸ì„œëŠ” /api/analyze-fileë¡œ
          analysis = await analyzeFile(base64, fileName, isPDF ? 'pdf' : 'document');
        }
        
        // âœ¨ v25: AIì§€ë‹ˆ ìë™ ì•ˆë‚´ ë©”ì‹œì§€
        addMessage(`ğŸ“‹ ë¶„ì„ ì™„ë£Œ!\n\n${analysis}\n\nğŸ’¬ ì´ íŒŒì¼ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.`, false);
        
        // ì»¨í…ìŠ¤íŠ¸ ì €ì¥ (ëŒ€í™”ì—ì„œ í™œìš©)
        const contextData = {
          id: Date.now(),
          fileName: fileName,
          fileType: isImage ? 'image' : (isPDF ? 'pdf' : 'document'),
          analysis: analysis,
          timestamp: new Date().toISOString()
        };
        
        setAnalysisContextList(prev => {
          const newList = [...prev, contextData];
          // WebSocketì— ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
          if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
            wsRef.current.send(JSON.stringify({
              type: 'update_context',
              analysisContextList: newList
            }));
          }
          return newList;
        });
        
      } catch (error) {
        console.error('íŒŒì¼ ì²˜ë¦¬ ì—ëŸ¬:', error);
        addMessage(`âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: ${file.name}`, false);
      }
    }
    
    setIsAnalyzing(false);
    setStatus('ëŒ€ê¸°ì¤‘');
    event.target.value = '';
  };

  const fileToBase64 = (file) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => resolve(reader.result);
      reader.onerror = (error) => reject(error);
    });
  };

  // ğŸ”§ v25: ì´ë¯¸ì§€ ë¶„ì„ API (ë³„ë„ í•¨ìˆ˜)
  const analyzeImage = async (base64Data, fileName) => {
    try {
      const response = await fetch(`${RENDER_SERVER}/api/analyze-image`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          image: base64Data,
          prompt: `ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. 
ë§Œì•½ ë³´í—˜ì¦ê¶Œ, ì˜ìˆ˜ì¦, ëª…í•¨, ì˜ë£Œë¹„ ì²­êµ¬ì„œ ë“±ì´ë¼ë©´:
1. ë¬¸ì„œ ìœ í˜•
2. í•µì‹¬ ì •ë³´ (ì´ë¦„, ê¸ˆì•¡, ë‚ ì§œ ë“±)
3. ë³´í—˜ ê´€ì ì—ì„œì˜ ì˜ë¯¸
ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.`
        })
      });
      
      const data = await response.json();
      
      if (data.success) {
        return data.analysis;
      } else {
        return `âŒ ë¶„ì„ ì‹¤íŒ¨: ${data.error}`;
      }
    } catch (error) {
      console.error('ì´ë¯¸ì§€ ë¶„ì„ API ì—ëŸ¬:', error);
      return 'âŒ ì„œë²„ ì—°ê²° ì˜¤ë¥˜. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
    }
  };

  // ğŸ”§ v25: íŒŒì¼/PDF ë¶„ì„ API
  const analyzeFile = async (base64Data, fileName, fileType) => {
    try {
      const response = await fetch(`${RENDER_SERVER}/api/analyze-file`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          file: base64Data,
          fileName: fileName,
          fileType: fileType
        })
      });
      
      const data = await response.json();
      
      if (data.success) {
        return data.analysis;
      } else {
        return `âŒ ë¶„ì„ ì‹¤íŒ¨: ${data.error}`;
      }
    } catch (error) {
      console.error('íŒŒì¼ ë¶„ì„ API ì—ëŸ¬:', error);
      return 'âŒ ì„œë²„ ì—°ê²° ì˜¤ë¥˜. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
    }
  };

  // ğŸ”§ v25: ì˜¤ë””ì˜¤ ì¬ìƒ (ì•ˆì •í™”)
  const playAudio = async (base64Audio) => {
    // ìŒì†Œê±° ìƒíƒœë©´ ë¬´ì‹œ
    if (muteServerAudioRef.current) return;
    
    audioQueueRef.current.push(base64Audio);
    if (!isPlayingRef.current) {
      processAudioQueue();
    }
  };

  const processAudioQueue = async () => {
    if (audioQueueRef.current.length === 0) {
      isPlayingRef.current = false;
      return;
    }
    
    isPlayingRef.current = true;
    const base64Audio = audioQueueRef.current.shift();
    
    try {
      // ğŸ”§ v25: AudioContext í™•ì‹¤íˆ ì´ˆê¸°í™”
      const initialized = await initAudioContext();
      if (!initialized) {
        console.error('AudioContext ì´ˆê¸°í™” ì‹¤íŒ¨');
        processAudioQueue();
        return;
      }
      
      const audioData = atob(base64Audio);
      const arrayBuffer = new ArrayBuffer(audioData.length);
      const view = new Uint8Array(arrayBuffer);
      for (let i = 0; i < audioData.length; i++) {
        view[i] = audioData.charCodeAt(i);
      }
      
      const pcm16 = new Int16Array(arrayBuffer);
      const float32 = new Float32Array(pcm16.length);
      for (let i = 0; i < pcm16.length; i++) {
        float32[i] = pcm16[i] / 32768;
      }
      
      const audioBuffer = audioContextRef.current.createBuffer(1, float32.length, 24000);
      audioBuffer.getChannelData(0).set(float32);
      
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      source.onended = () => processAudioQueue();
      source.start();
      
    } catch (e) {
      console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì—ëŸ¬:', e);
      processAudioQueue();
    }
  };

  const cleanupVoiceMode = () => {
    if (wsRef.current) {
      try {
        wsRef.current.send(JSON.stringify({ type: 'stop' }));
        wsRef.current.close();
      } catch (e) {}
      wsRef.current = null;
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    
    if (processorRef.current) {
      try {
        const { processor, source, audioContext } = processorRef.current;
        processor.disconnect();
        source.disconnect();
        audioContext.close();
      } catch (e) {}
      processorRef.current = null;
    }
    
    audioQueueRef.current = [];
    isPlayingRef.current = false;
    isConnectedRef.current = false;
  };

  const checkCallCommand = (text) => {
    const phoneMatch = text.match(/\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}/);
    if (!phoneMatch) return null;
    
    const phone = phoneMatch[0];
    
    let name = 'ê³ ê°';
    const nameMatch = text.match(/([ê°€-í£]{2,4})/g);
    if (nameMatch) {
      const excludeWords = ['ì „í™”', 'í†µí™”', 'ì—°ê²°', 'í•´ì¤˜', 'í•´ì£¼ì„¸ìš”', 'ë¶€íƒ', 'ì…ë‹ˆë‹¤', 'ì—ê²Œ', 'í•œí…Œ', 'ë²ˆí˜¸', 'ì—°ë½', 'ê³ ê°', 'ìƒë‹´', 'ì˜ˆì•½', 'ë³´í—˜', 'ê³„ì•½'];
      for (const n of nameMatch) {
        if (!excludeWords.includes(n)) {
          name = n;
          break;
        }
      }
    }
    
    let purpose = 'ìƒë‹´ ì¼ì • ì˜ˆì•½';
    if (text.includes('ë³´í—˜') && text.includes('ìƒë‹´')) purpose = 'ë³´í—˜ ìƒë‹´';
    else if (text.includes('ê³„ì•½')) purpose = 'ê³„ì•½ ê´€ë ¨ ìƒë‹´';
    else if (text.includes('ì²­êµ¬')) purpose = 'ë³´í—˜ê¸ˆ ì²­êµ¬ ì•ˆë‚´';
    else if (text.includes('ê°±ì‹ ')) purpose = 'ë³´í—˜ ê°±ì‹  ì•ˆë‚´';
    else if (text.includes('ë§Œê¸°')) purpose = 'ë§Œê¸° ì•ˆë‚´';
    else if (text.includes('ìƒë‹´')) purpose = 'ìƒë‹´ ì¼ì • ì˜ˆì•½';
    
    return { name, phone, purpose };
  };

  const checkApproval = (text) => {
    const approvalWords = ['ê·¸ë˜', 'ì‘', 'ì–´', 'í•´ì¤˜', 'í•´ì£¼ì„¸ìš”', 'ì§„í–‰', 'ë„¤', 'ì¢‹ì•„', 'ì•Œì•˜ì–´', 'ì˜¤ì¼€ì´', 'ok', 'ê±¸ì–´', 'ì „í™”í•´'];
    const lowerText = text.toLowerCase();
    return approvalWords.some(word => lowerText.includes(word));
  };

  const checkRejection = (text) => {
    const rejectionWords = ['ì•„ë‹ˆ', 'ì·¨ì†Œ', 'ì•ˆí•´', 'í•˜ì§€ë§ˆ', 'ëì–´', 'ê·¸ë§Œ'];
    return rejectionWords.some(word => text.includes(word));
  };

  // ğŸ”§ v25: ìŒì„± ëª¨ë“œ ì‹œì‘ (ì•ˆì •í™”)
  const startVoiceMode = async () => {
    if (currentCall) return;
    if (isConnectedRef.current) return;
    
    // ìƒíƒœ ì´ˆê¸°í™”
    lastCallInfoRef.current = null;
    setPendingCall(null);
    muteServerAudioRef.current = false;
    
    try {
      setStatus('ì—°ê²°ì¤‘...');
      setIsVoiceMode(true);
      
      // ğŸ”§ v25: AudioContext ë¨¼ì € ì´ˆê¸°í™” (ì‚¬ìš©ì ì œìŠ¤ì²˜ì—ì„œ)
      await initAudioContext();
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: { sampleRate: 24000, channelCount: 1, echoCancellation: true, noiseSuppression: true } 
      });
      mediaStreamRef.current = stream;
      
      const ws = new WebSocket(`${WS_SERVER}?mode=app`);
      wsRef.current = ws;
      
      ws.onopen = () => {
        console.log('ğŸ”Œ WebSocket ì—°ê²°ë¨');
        const startMessage = { 
          type: 'start_app',
          analysisContextList: analysisContextList
        };
        ws.send(JSON.stringify(startMessage));
      };
      
      ws.onmessage = (event) => {
        try {
          const msg = JSON.parse(event.data);
          
          if (msg.type === 'session_started') {
            isConnectedRef.current = true;
            setStatus('ë“£ëŠ”ì¤‘...');
            console.log('âœ… OpenAI ì„¸ì…˜ ì‹œì‘ë¨');
            startAudioCapture(stream, ws);
          }
          
          if (msg.type === 'audio' && msg.data) {
            playAudio(msg.data);
          }
          
          if (msg.type === 'transcript' && msg.role === 'user') {
            addMessage(msg.text, true);
            
            // ğŸ”§ v25: ì „í™” ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¼ ë•Œ
            if (lastCallInfoRef.current) {
              if (checkApproval(msg.text)) {
                const callInfo = lastCallInfoRef.current;
                lastCallInfoRef.current = null;
                setPendingCall(null);
                muteServerAudioRef.current = false;
                addMessage(`ë„¤, ${callInfo.name}ë‹˜ê»˜ ì „í™”í•˜ê² ìŠµë‹ˆë‹¤.`, false);
                makeCall(callInfo.name, callInfo.phone, callInfo.purpose);
                return;
              } else if (checkRejection(msg.text)) {
                lastCallInfoRef.current = null;
                setPendingCall(null);
                muteServerAudioRef.current = false;
                addMessage('ë„¤, ì „í™”ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.', false);
                return;
              }
            }
            
            // ì „í™” ëª…ë ¹ ê°ì§€
            const callInfo = checkCallCommand(msg.text);
            if (callInfo) {
              muteServerAudioRef.current = true;
              setPendingCall(callInfo);
              lastCallInfoRef.current = callInfo;
              addMessage(`${callInfo.name}ë‹˜ê»˜ ${callInfo.purpose} ëª©ì ìœ¼ë¡œ ì „í™”í• ê¹Œìš”? (ë„¤/ì•„ë‹ˆì˜¤)`, false);
              return;
            }
            
            // ì†Œí†µ ëª…ë ¹ ê°ì§€
            const commInfo = checkCommCommand(msg.text);
            if (commInfo) {
              setPendingComm(commInfo);
              const typeLabels = { kakao: 'ì¹´ì¹´ì˜¤í†¡', sms: 'ë¬¸ì', email: 'ì´ë©”ì¼', fax: 'íŒ©ìŠ¤' };
              addMessage(`${commInfo.name}ë‹˜ê»˜ ${typeLabels[commInfo.type]}ì„ ë³´ë‚¼ê¹Œìš”? (ë„¤/ì•„ë‹ˆì˜¤)`, false);
              return;
            }
          }
          
          if (msg.type === 'transcript' && msg.role === 'assistant') {
            if (lastCallInfoRef.current) return; // ì „í™” ëŒ€ê¸° ì¤‘ì—” AI ì‘ë‹µ ë¬´ì‹œ
            addMessage(msg.text, false);
          }
          
          if (msg.type === 'interrupt') {
            audioQueueRef.current = [];
            isPlayingRef.current = false;
          }
          
          if (msg.type === 'error') {
            console.error('ì„œë²„ ì—ëŸ¬:', msg.error);
            addMessage(`âš ï¸ ì—°ê²° ì˜¤ë¥˜: ${msg.error}`, false);
          }
          
        } catch (e) {
          console.error('ë©”ì‹œì§€ íŒŒì‹± ì—ëŸ¬:', e);
        }
      };
      
      ws.onerror = (error) => {
        console.error('WebSocket ì—ëŸ¬:', error);
        setStatus('ì—°ê²° ì‹¤íŒ¨');
        cleanupVoiceMode();
        setIsVoiceMode(false);
      };
      
      ws.onclose = () => {
        console.log('ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ');
        isConnectedRef.current = false;
        setStatus('ëŒ€ê¸°ì¤‘');
        setIsVoiceMode(false);
      };
      
    } catch (error) {
      console.error('ë§ˆì´í¬ ì—ëŸ¬:', error);
      alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      cleanupVoiceMode();
      setIsVoiceMode(false);
      setStatus('ëŒ€ê¸°ì¤‘');
    }
  };

  const startAudioCapture = (stream, ws) => {
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      
      processor.onaudioprocess = (e) => {
        if (!ws || ws.readyState !== WebSocket.OPEN) return;
        
        const inputData = e.inputBuffer.getChannelData(0);
        const pcm16 = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
        }
        
        const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
        ws.send(JSON.stringify({ type: 'audio', data: base64 }));
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      processorRef.current = { processor, source, audioContext };
    } catch (e) {
      console.error('ì˜¤ë””ì˜¤ ìº¡ì²˜ ì—ëŸ¬:', e);
    }
  };

  const stopVoiceMode = () => {
    cleanupVoiceMode();
    setIsVoiceMode(false);
    setStatus('ëŒ€ê¸°ì¤‘');
    setPendingCall(null);
    muteServerAudioRef.current = false;
  };

  const makeCall = async (name, phone, purpose = 'ìƒë‹´ ì¼ì • ì˜ˆì•½') => {
    stopVoiceMode();
    setStatus('ì „í™” ì—°ê²°ì¤‘...');
    
    lastCallInfoRef.current = null;
    setPendingCall(null);
    
    try {
      const formattedPhone = phone.replace(/[-\s]/g, '');
      const fullPhone = formattedPhone.startsWith('0') ? '+82' + formattedPhone.slice(1) : formattedPhone;
      
      const response = await fetch(`${RENDER_SERVER}/api/call`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          phoneNumber: fullPhone, 
          customerName: name,
          purpose: purpose
        })
      });
      const data = await response.json();
      
      if (data.success) {
        setCurrentCall({ name, phone, callSid: data.callSid, purpose });
        setCallDuration(0);
        setStatus('í†µí™”ì¤‘');
        
        callTimerRef.current = setInterval(() => {
          setCallDuration(prev => prev + 1);
        }, 1000);
        
        addMessage(`ğŸ“ ${name}ë‹˜ê»˜ ${purpose} ëª©ì ìœ¼ë¡œ ì „í™” ì—°ê²°ë¨ (AI ëŒ€í™”)`, false);
      } else {
        addMessage(`âŒ ì—°ê²° ì‹¤íŒ¨: ${data.error}`, false);
        setStatus('ëŒ€ê¸°ì¤‘');
      }
    } catch (error) {
      console.error('ì „í™” ì—ëŸ¬:', error);
      addMessage('â³ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.', false);
      setStatus('ëŒ€ê¸°ì¤‘');
    }
  };

  const endCall = async () => {
    if (callTimerRef.current) {
      clearInterval(callTimerRef.current);
      callTimerRef.current = null;
    }
    
    const name = currentCall?.name || 'ê³ ê°';
    const callSid = currentCall?.callSid;
    const duration = formatDuration(callDuration);
    
    if (callSid) {
      try {
        await fetch(`${RENDER_SERVER}/api/end-call/${callSid}`, { method: 'POST' });
      } catch (e) {
        console.error('í†µí™” ì¢…ë£Œ API ì—ëŸ¬:', e);
      }
    }
    
    setCurrentCall(null);
    setCallDuration(0);
    setStatus('ëŒ€ê¸°ì¤‘');
    
    addMessage(`ğŸ“´ ${name}ë‹˜ í†µí™” ì¢…ë£Œ (${duration})`, false);
  };

  const formatDuration = (seconds) => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}ë¶„ ${s}ì´ˆ`;
  };

  const handleSend = async () => {
    if (!inputText.trim()) return;
    const text = inputText;
    setInputText('');
    
    addMessage(text, true);
    
    // ì „í™” ìŠ¹ì¸ ëŒ€ê¸°
    if (pendingCall) {
      if (checkApproval(text)) {
        const callInfo = pendingCall;
        setPendingCall(null);
        addMessage(`ë„¤, ${callInfo.name}ë‹˜ê»˜ ì „í™”í•˜ê² ìŠµë‹ˆë‹¤.`, false);
        await makeCall(callInfo.name, callInfo.phone, callInfo.purpose);
        return;
      } else if (checkRejection(text)) {
        setPendingCall(null);
        addMessage('ë„¤, ì „í™”ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.', false);
        return;
      }
    }
    
    // ì†Œí†µ ìŠ¹ì¸ ëŒ€ê¸°
    if (pendingComm) {
      if (checkApproval(text)) {
        handleCommApprove();
        return;
      } else if (checkRejection(text)) {
        handleCommCancel();
        return;
      }
    }
    
    // ì „í™” ëª…ë ¹ ê°ì§€
    const callInfo = checkCallCommand(text);
    if (callInfo) {
      setPendingCall(callInfo);
      addMessage(`${callInfo.name}ë‹˜ê»˜ ${callInfo.purpose} ëª©ì ìœ¼ë¡œ ì „í™”í• ê¹Œìš”?`, false);
      return;
    }
    
    // ì†Œí†µ ëª…ë ¹ ê°ì§€
    const commInfo = checkCommCommand(text);
    if (commInfo) {
      setPendingComm(commInfo);
      const typeLabels = { kakao: 'ì¹´ì¹´ì˜¤í†¡', sms: 'ë¬¸ì', email: 'ì´ë©”ì¼', fax: 'íŒ©ìŠ¤' };
      addMessage(`${commInfo.name}ë‹˜ê»˜ ${typeLabels[commInfo.type]}ì„ ë³´ë‚¼ê¹Œìš”?`, false);
      return;
    }
    
    setStatus('ìƒê°ì¤‘...');
    
    try {
      // ğŸ”§ v25: ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ í¬í•¨í•˜ì—¬ ì „ì†¡
      const response = await fetch(`${RENDER_SERVER}/api/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          message: text,
          analysisContext: analysisContextList.length > 0 ? analysisContextList : null
        })
      });
      const data = await response.json();
      addMessage(data.reply, false);
    } catch (error) {
      addMessage('ë„¤, ëŒ€í‘œë‹˜!', false);
    }
    
    setStatus('ëŒ€ê¸°ì¤‘');
  };

  return (
    <div className="agent-page">
      <header className="agent-header">
        <div className="header-left">
          <div className="header-icon">ğŸ§</div>
          <div className="header-info">
            <h1>AI ì§€ë‹ˆ</h1>
            <span className="header-subtitle">40ë§Œ ë³´í—˜ì„¤ê³„ì‚¬ì˜ AI ë¹„ì„œ</span>
          </div>
        </div>
        <div className={`status-badge ${isVoiceMode ? 'voice-mode' : currentCall ? 'oncall' : ''}`}>
          {status}
        </div>
      </header>

      {currentCall && (
        <div className="call-banner">
          <div className="call-info">
            <span className="call-icon">ğŸ“</span>
            <span>{currentCall.name}ë‹˜ í†µí™”ì¤‘</span>
            <span className="call-duration">{formatDuration(callDuration)}</span>
          </div>
          <button className="end-call-btn" onClick={endCall}>ì¢…ë£Œ</button>
        </div>
      )}

      {isVoiceMode && !currentCall && (
        <div className="voice-banner">
          <div className="voice-info">
            <span className="voice-icon">ğŸ™ï¸</span>
            <span>AI ì§€ë‹ˆì™€ ëŒ€í™”ì¤‘</span>
          </div>
          <button className="stop-voice-btn" onClick={stopVoiceMode}>ì¢…ë£Œ</button>
        </div>
      )}

      {pendingCall && (
        <div className="pending-call-banner">
          <div className="pending-info">
            <span>ğŸ“ {pendingCall.name}ë‹˜ê»˜ ì „í™”í• ê¹Œìš”?</span>
          </div>
          <div className="pending-buttons">
            <button className="approve-btn" onClick={() => {
              const callInfo = pendingCall;
              setPendingCall(null);
              lastCallInfoRef.current = null;
              muteServerAudioRef.current = false;
              addMessage(`ë„¤, ${callInfo.name}ë‹˜ê»˜ ì „í™”í•˜ê² ìŠµë‹ˆë‹¤.`, false);
              makeCall(callInfo.name, callInfo.phone, callInfo.purpose);
            }}>ë„¤</button>
            <button className="reject-btn" onClick={() => {
              setPendingCall(null);
              lastCallInfoRef.current = null;
              muteServerAudioRef.current = false;
              addMessage('ë„¤, ì „í™”ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.', false);
            }}>ì•„ë‹ˆì˜¤</button>
          </div>
        </div>
      )}

      {pendingComm && (
        <div className="pending-call-banner" style={{ background: 'linear-gradient(135deg, #3B82F6, #2563eb)' }}>
          <div className="pending-info">
            <span>{getCommTypeInfo(pendingComm.type).icon} {pendingComm.name}ë‹˜ê»˜ {getCommTypeInfo(pendingComm.type).label} ë³´ë‚¼ê¹Œìš”?</span>
          </div>
          <div className="pending-buttons">
            <button className="approve-btn" onClick={handleCommApprove}>ë„¤</button>
            <button className="reject-btn" onClick={handleCommCancel}>ì•„ë‹ˆì˜¤</button>
          </div>
        </div>
      )}

      <div className="chat-area" ref={chatAreaRef}>
        {messages.length === 0 ? (
          <div className="welcome-message">
            <div className="welcome-icon">ğŸ§</div>
            <h2>ì•ˆë…•í•˜ì„¸ìš”, ì§€ë‹ˆì…ë‹ˆë‹¤!</h2>
            <p>ğŸ™ï¸ ë²„íŠ¼ ëˆ„ë¥´ê³  ììœ ë¡­ê²Œ ë§ì”€í•˜ì„¸ìš”.</p>
            <p>ğŸ“ íŒŒì¼ ë²„íŠ¼ìœ¼ë¡œ ë³´í—˜ì¦ê¶Œì„ ë¶„ì„í•´ë³´ì„¸ìš”.</p>
          </div>
        ) : (
          <>
            {messages.map((msg) => (
              <div key={msg.id} className={`message ${msg.isUser ? 'user' : 'ai'}`}>
                <div className="message-content">
                  {msg.imageData && (
                    <img 
                      src={msg.imageData} 
                      alt="ì—…ë¡œë“œëœ ì´ë¯¸ì§€" 
                      className="message-image"
                      onClick={() => window.open(msg.imageData, '_blank')}
                    />
                  )}
                  <p>{msg.text}</p>
                  <span className="message-time">{msg.time}</span>
                </div>
              </div>
            ))}
          </>
        )}
        
        {isAnalyzing && (
          <div className="message ai">
            <div className="message-content">
              <p>ğŸ” íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      <div className="quick-actions">
        <button onClick={() => { if (!isVoiceMode && !currentCall) startVoiceMode(); }} disabled={!!currentCall}>ğŸ§ ì§€ë‹ˆì•¼</button>
        <button disabled={!currentCall} onClick={endCall}>ğŸ“´ í†µí™”ì¢…ë£Œ</button>
      </div>

      <div className="input-area">
        <input type="file" ref={cameraInputRef} onChange={handleFileSelect} accept="image/*" capture="environment" style={{ display: 'none' }} />
        <input type="file" ref={imageInputRef} onChange={handleFileSelect} accept="image/*" multiple style={{ display: 'none' }} />
        <input type="file" ref={fileInputRef} onChange={handleFileSelect} accept=".pdf,.doc,.docx,.xls,.xlsx,.hwp,.txt" multiple style={{ display: 'none' }} />
        
        {showFileMenu && (
          <div className="file-submenu">
            <button className="submenu-btn" onClick={() => { cameraInputRef.current?.click(); setShowFileMenu(false); }}>
              <span>ğŸ“·</span><span>ì‚¬ì§„ì´¬ì˜</span>
            </button>
            <button className="submenu-btn" onClick={() => { imageInputRef.current?.click(); setShowFileMenu(false); }}>
              <span>ğŸ–¼ï¸</span><span>ì‚¬ì§„/ì´ë¯¸ì§€</span>
            </button>
            <button className="submenu-btn" onClick={() => { fileInputRef.current?.click(); setShowFileMenu(false); }}>
              <span>ğŸ“</span><span>íŒŒì¼ì²¨ë¶€</span>
            </button>
            {analysisContextList.length > 0 && (
              <button className="submenu-btn submenu-clear" onClick={() => { clearAnalysisContext(); setShowFileMenu(false); }}>
                <span>ğŸ—‘ï¸</span><span>ì´ˆê¸°í™” ({analysisContextList.length})</span>
              </button>
            )}
            <button className="submenu-close" onClick={() => setShowFileMenu(false)}>âœ•</button>
          </div>
        )}
        
        <div className="action-buttons">
          <button className={`action-btn ${showFileMenu ? 'active' : ''}`} disabled={!!currentCall || isVoiceMode || isAnalyzing} onClick={() => setShowFileMenu(!showFileMenu)}>
            <span className="action-icon">ğŸ“</span><span className="action-label">íŒŒì¼</span>
          </button>
          <button className={`action-btn voice ${isVoiceMode ? 'active' : ''}`} onClick={isVoiceMode ? stopVoiceMode : startVoiceMode} disabled={!!currentCall || isAnalyzing}>
            <span className="action-icon">{isVoiceMode ? 'ğŸ”´' : 'ğŸ¤'}</span><span className="action-label">ë³´ì´ìŠ¤</span>
          </button>
          <button className="action-btn" disabled>
            <span className="action-icon">ğŸ”´</span><span className="action-label">ë…¹ìŒ</span>
          </button>
        </div>
        
        <div className="input-row">
          <input type="text" placeholder="í…ìŠ¤íŠ¸ë¡œ ì…ë ¥..." value={inputText} onChange={(e) => setInputText(e.target.value)} onKeyPress={(e) => e.key === 'Enter' && handleSend()} disabled={isVoiceMode || isAnalyzing} />
          <button className="send-btn" onClick={handleSend} disabled={isVoiceMode || isAnalyzing}>â¤</button>
        </div>
      </div>

      {showCommOverlay && commTarget && (
        <div className="comm-overlay">
          <div className="comm-header" style={{ background: getCommTypeInfo(commType).color }}>
            <button className="comm-back" onClick={closeCommOverlay} style={{ color: getCommTypeInfo(commType).textColor }}>â†</button>
            <span style={{ color: getCommTypeInfo(commType).textColor }}>{getCommTypeInfo(commType).icon} {getCommTypeInfo(commType).label} ë°œì†¡</span>
          </div>
          <div className="comm-content">
            <div className="comm-recipient">
              <div className="comm-avatar">{commTarget.name?.charAt(0) || '?'}</div>
              <div className="comm-info">
                <h4>{commTarget.name}</h4>
                <p>{commTarget.phone}</p>
              </div>
            </div>
            <div className="comm-preview">
              <div className="comm-preview-header">ğŸ“ ë°œì†¡ ë‚´ìš©</div>
              <div className="comm-preview-text">
                ì•ˆë…•í•˜ì„¸ìš”, {commTarget.name}ë‹˜!<br /><br />
                ì§€ë‚œë²ˆ ìƒë‹´ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.<br />
                ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ ìˆìœ¼ì‹œë©´ ì—°ë½ ì£¼ì„¸ìš”.<br /><br />
                - ì˜¤ì›íŠ¸ê¸ˆìœµì—°êµ¬ì†Œ ë“œë¦¼
              </div>
            </div>
            <div className={`comm-status ${commStatus}`}>
              {commStatus === 'ready' && <><span className="comm-status-icon">ğŸ“¤</span><span>ë°œì†¡ ì¤€ë¹„ ì™„ë£Œ</span></>}
              {commStatus === 'sending' && <><span className="comm-status-icon spinning">â³</span><span>ë°œì†¡ ì¤‘...</span></>}
              {commStatus === 'sent' && <><span className="comm-status-icon">âœ…</span><span>{getCommTypeInfo(commType).label} ë°œì†¡ ì™„ë£Œ!</span></>}
            </div>
          </div>
        </div>
      )}
    </div>
  );
}

export default AgentPage;
