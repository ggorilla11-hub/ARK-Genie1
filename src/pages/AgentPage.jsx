import React, { useState, useRef, useEffect } from 'react';
import './AgentPage.css';

const RENDER_SERVER = 'https://ark-genie-server.onrender.com';
const WS_SERVER = 'wss://ark-genie-server.onrender.com';

function AgentPage() {
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [isVoiceMode, setIsVoiceMode] = useState(false);
  const [status, setStatus] = useState('ëŒ€ê¸°ì¤‘');
  const [currentCall, setCurrentCall] = useState(null);
  const [callDuration, setCallDuration] = useState(0);
  
  const chatAreaRef = useRef(null);
  const wsRef = useRef(null);
  const audioContextRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const processorRef = useRef(null);
  const callTimerRef = useRef(null);
  const audioQueueRef = useRef([]);
  const isPlayingRef = useRef(false);
  const isConnectedRef = useRef(false);

  useEffect(() => {
    if (chatAreaRef.current) {
      chatAreaRef.current.scrollTop = chatAreaRef.current.scrollHeight;
    }
  }, [messages]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      cleanupVoiceMode();
      if (callTimerRef.current) clearInterval(callTimerRef.current);
    };
  }, []);

  const addMessage = (text, isUser) => {
    setMessages(prev => [...prev, {
      id: Date.now() + Math.random(),
      text,
      isUser,
      time: new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
    }]);
  };

  // ì‹ í˜¸ìŒ ì¬ìƒ (ë§ˆì´í¬ ì—°ê²° ì•Œë¦¼)
  const playBeep = (type = 'start') => {
    try {
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const oscillator = audioCtx.createOscillator();
      const gainNode = audioCtx.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(audioCtx.destination);
      
      if (type === 'start') {
        // ì‹œì‘ìŒ: ë†’ì€ ìŒ ë‘ ë²ˆ
        oscillator.frequency.value = 800;
        gainNode.gain.value = 0.3;
        oscillator.start();
        oscillator.stop(audioCtx.currentTime + 0.1);
        
        setTimeout(() => {
          const osc2 = audioCtx.createOscillator();
          const gain2 = audioCtx.createGain();
          osc2.connect(gain2);
          gain2.connect(audioCtx.destination);
          osc2.frequency.value = 1000;
          gain2.gain.value = 0.3;
          osc2.start();
          osc2.stop(audioCtx.currentTime + 0.15);
        }, 150);
      } else {
        // ì¢…ë£ŒìŒ: ë‚®ì€ ìŒ í•œ ë²ˆ
        oscillator.frequency.value = 400;
        gainNode.gain.value = 0.3;
        oscillator.start();
        oscillator.stop(audioCtx.currentTime + 0.2);
      }
    } catch (e) {
      console.log('ì‹ í˜¸ìŒ ì¬ìƒ ì‹¤íŒ¨:', e);
    }
  };

  // Base64 ì˜¤ë””ì˜¤ ì¬ìƒ
  const playAudio = async (base64Audio) => {
    audioQueueRef.current.push(base64Audio);
    if (!isPlayingRef.current) {
      processAudioQueue();
    }
  };

  const processAudioQueue = async () => {
    if (audioQueueRef.current.length === 0) {
      isPlayingRef.current = false;
      return;
    }
    
    isPlayingRef.current = true;
    const base64Audio = audioQueueRef.current.shift();
    
    try {
      if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      }
      
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
      }
      
      const audioData = atob(base64Audio);
      const arrayBuffer = new ArrayBuffer(audioData.length);
      const view = new Uint8Array(arrayBuffer);
      for (let i = 0; i < audioData.length; i++) {
        view[i] = audioData.charCodeAt(i);
      }
      
      // PCM16 to Float32
      const pcm16 = new Int16Array(arrayBuffer);
      const float32 = new Float32Array(pcm16.length);
      for (let i = 0; i < pcm16.length; i++) {
        float32[i] = pcm16[i] / 32768;
      }
      
      const audioBuffer = audioContextRef.current.createBuffer(1, float32.length, 24000);
      audioBuffer.getChannelData(0).set(float32);
      
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      source.onended = () => processAudioQueue();
      source.start();
    } catch (e) {
      console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì—ëŸ¬:', e);
      processAudioQueue();
    }
  };

  // ì •ë¦¬ í•¨ìˆ˜
  const cleanupVoiceMode = () => {
    // WebSocket ì¢…ë£Œ
    if (wsRef.current) {
      try {
        wsRef.current.send(JSON.stringify({ type: 'stop' }));
        wsRef.current.close();
      } catch (e) {}
      wsRef.current = null;
    }
    
    // ë§ˆì´í¬ ì¢…ë£Œ
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    
    // ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì¢…ë£Œ
    if (processorRef.current) {
      try {
        const { processor, source, audioContext } = processorRef.current;
        processor.disconnect();
        source.disconnect();
        audioContext.close();
      } catch (e) {}
      processorRef.current = null;
    }
    
    // ì˜¤ë””ì˜¤ í ì´ˆê¸°í™”
    audioQueueRef.current = [];
    isPlayingRef.current = false;
    isConnectedRef.current = false;
  };

  // WebSocket ì—°ê²° ë° Realtime API ì‹œì‘
  const startVoiceMode = async () => {
    // ì´ë¯¸ ì—°ê²° ì¤‘ì´ë©´ ë¬´ì‹œ
    if (isConnectedRef.current) {
      console.log('ì´ë¯¸ ì—°ê²°ë¨');
      return;
    }
    
    try {
      setStatus('ì—°ê²°ì¤‘...');
      setIsVoiceMode(true);
      
      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      mediaStreamRef.current = stream;
      
      // WebSocket ì—°ê²°
      const ws = new WebSocket(`${WS_SERVER}?mode=app`);
      wsRef.current = ws;
      
      ws.onopen = () => {
        console.log('âœ… WebSocket ì—°ê²°ë¨');
        ws.send(JSON.stringify({ type: 'start_app' }));
      };
      
      ws.onmessage = (event) => {
        try {
          const msg = JSON.parse(event.data);
          
          // ì„¸ì…˜ ì‹œì‘ë¨ - ë§ˆì´í¬ ì—°ê²° ì‹ í˜¸ìŒ
          if (msg.type === 'session_started') {
            console.log('âœ… ì„¸ì…˜ ì‹œì‘ë¨');
            isConnectedRef.current = true;
            setStatus('ë“£ëŠ”ì¤‘...');
            playBeep('start');
            startAudioCapture(stream, ws);
          }
          
          // ì˜¤ë””ì˜¤ ìˆ˜ì‹ 
          if (msg.type === 'audio' && msg.data) {
            playAudio(msg.data);
          }
          
          // ì‚¬ìš©ì ìŒì„± í…ìŠ¤íŠ¸ (ë¨¼ì € í‘œì‹œ)
          if (msg.type === 'transcript' && msg.role === 'user') {
            addMessage(msg.text, true);
          }
          
          // ì§€ë‹ˆ ì‘ë‹µ í…ìŠ¤íŠ¸ (ë‚˜ì¤‘ì— í‘œì‹œ)
          if (msg.type === 'transcript' && msg.role === 'assistant') {
            addMessage(msg.text, false);
            
            // ì „í™” ëª…ë ¹ ê°ì§€
            checkCallCommand(msg.text);
          }
          
          // AI ì¤‘ë‹¨ (Barge-in)
          if (msg.type === 'interrupt') {
            audioQueueRef.current = [];
            isPlayingRef.current = false;
          }
          
          // ì—ëŸ¬
          if (msg.type === 'error') {
            console.error('ì„œë²„ ì—ëŸ¬:', msg.error);
            addMessage('âš ï¸ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.', false);
          }
          
          // OpenAI ì—°ê²° ì¢…ë£Œ
          if (msg.type === 'openai_closed') {
            console.log('OpenAI ì—°ê²° ì¢…ë£Œë¨');
          }
          
        } catch (e) {
          console.error('ë©”ì‹œì§€ íŒŒì‹± ì—ëŸ¬:', e);
        }
      };
      
      ws.onerror = (error) => {
        console.error('âŒ WebSocket ì—ëŸ¬:', error);
        setStatus('ì—°ê²° ì‹¤íŒ¨');
        cleanupVoiceMode();
        setIsVoiceMode(false);
      };
      
      ws.onclose = () => {
        console.log('ğŸ”Œ WebSocket ì¢…ë£Œ');
        isConnectedRef.current = false;
        if (isVoiceMode) {
          setStatus('ëŒ€ê¸°ì¤‘');
          setIsVoiceMode(false);
        }
      };
      
    } catch (error) {
      console.error('ë§ˆì´í¬ ì—ëŸ¬:', error);
      alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      cleanupVoiceMode();
      setIsVoiceMode(false);
      setStatus('ëŒ€ê¸°ì¤‘');
    }
  };

  // ë§ˆì´í¬ ì˜¤ë””ì˜¤ ìº¡ì²˜ ë° ì „ì†¡
  const startAudioCapture = (stream, ws) => {
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      
      processor.onaudioprocess = (e) => {
        if (!ws || ws.readyState !== WebSocket.OPEN) return;
        
        const inputData = e.inputBuffer.getChannelData(0);
        const pcm16 = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
        }
        
        const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
        ws.send(JSON.stringify({ type: 'audio', data: base64 }));
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      processorRef.current = { processor, source, audioContext };
    } catch (e) {
      console.error('ì˜¤ë””ì˜¤ ìº¡ì²˜ ì—ëŸ¬:', e);
    }
  };

  // ì „í™” ëª…ë ¹ ê°ì§€ (ì§€ë‹ˆ ì‘ë‹µì—ì„œ)
  const checkCallCommand = (text) => {
    if (text.includes('ì „í™”í•©ë‹ˆë‹¤') || text.includes('ì „í™”í•˜ê² ìŠµë‹ˆë‹¤') || text.includes('ì „í™” ì—°ê²°')) {
      // ì „í™”ë²ˆí˜¸ì™€ ì´ë¦„ ì¶”ì¶œì€ ì´ì „ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ
      const lastUserMsg = messages.filter(m => m.isUser).pop();
      if (lastUserMsg) {
        const phoneMatch = lastUserMsg.text.match(/\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4}/);
        const nameMatch = lastUserMsg.text.match(/([ê°€-í£]{2,4})\s*(êµìˆ˜|ì„ ìƒ|ë‹˜|ì”¨|ê³ ê°|ëŒ€í‘œ)?/);
        
        if (phoneMatch) {
          const phone = phoneMatch[0];
          const name = nameMatch ? nameMatch[1] : 'ê³ ê°';
          
          setTimeout(() => {
            makeCall(name, phone);
          }, 2000);
        }
      }
    }
  };

  // ë³´ì´ìŠ¤ ëª¨ë“œ ì¢…ë£Œ
  const stopVoiceMode = () => {
    playBeep('stop');
    cleanupVoiceMode();
    setIsVoiceMode(false);
    setStatus('ëŒ€ê¸°ì¤‘');
  };

  // ì „í™” ê±¸ê¸°
  const makeCall = async (name, phone) => {
    stopVoiceMode();
    setStatus('ì „í™” ì—°ê²°ì¤‘...');
    
    try {
      const formattedPhone = phone.replace(/[-\s]/g, '');
      const fullPhone = formattedPhone.startsWith('0') ? '+82' + formattedPhone.slice(1) : formattedPhone;
      
      const response = await fetch(`${RENDER_SERVER}/api/call`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ to: fullPhone, customerName: name })
      });
      const data = await response.json();
      
      if (data.success) {
        setCurrentCall({ name, phone, callSid: data.callSid });
        setCallDuration(0);
        setStatus('í†µí™”ì¤‘');
        
        callTimerRef.current = setInterval(() => {
          setCallDuration(prev => prev + 1);
        }, 1000);
        
        addMessage(`ğŸ“ ${name}ë‹˜ í†µí™” ì—°ê²°ë¨`, false);
      } else {
        addMessage(`âŒ ì—°ê²° ì‹¤íŒ¨: ${data.error}`, false);
        setStatus('ëŒ€ê¸°ì¤‘');
      }
    } catch (error) {
      console.error('ì „í™” ì—ëŸ¬:', error);
      addMessage('â³ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.', false);
      setStatus('ëŒ€ê¸°ì¤‘');
    }
  };

  // ì „í™” ì¢…ë£Œ
  const endCall = () => {
    // íƒ€ì´ë¨¸ ì •ë¦¬
    if (callTimerRef.current) {
      clearInterval(callTimerRef.current);
      callTimerRef.current = null;
    }
    
    const name = currentCall?.name || 'ê³ ê°';
    const duration = formatDuration(callDuration);
    
    // ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”
    setCurrentCall(null);
    setCallDuration(0);
    setStatus('ëŒ€ê¸°ì¤‘');
    setIsVoiceMode(false);
    
    // ì •ë¦¬
    cleanupVoiceMode();
    
    addMessage(`ğŸ“´ ${name}ë‹˜ í†µí™” ì¢…ë£Œ (${duration})`, false);
  };

  const formatDuration = (seconds) => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}ë¶„ ${s}ì´ˆ`;
  };

  // í…ìŠ¤íŠ¸ ì „ì†¡ (ë°±ì—…ìš©)
  const handleSend = async () => {
    if (!inputText.trim()) return;
    const text = inputText;
    setInputText('');
    
    addMessage(text, true);
    setStatus('ìƒê°ì¤‘...');
    
    try {
      const response = await fetch(`${RENDER_SERVER}/api/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: text })
      });
      const data = await response.json();
      addMessage(data.reply, false);
    } catch (error) {
      addMessage('ë„¤, ëŒ€í‘œë‹˜!', false);
    }
    
    setStatus('ëŒ€ê¸°ì¤‘');
  };

  return (
    <div className="agent-page">
      <header className="agent-header">
        <div className="header-left">
          <div className="header-icon">ğŸ§</div>
          <div className="header-info">
            <h1>AI ì§€ë‹ˆ</h1>
            <span className="header-subtitle">40ë§Œ ë³´í—˜ì„¤ê³„ì‚¬ì˜ AI ë¹„ì„œ</span>
          </div>
        </div>
        <div className={`status-badge ${isVoiceMode ? 'voice-mode' : currentCall ? 'oncall' : ''}`}>
          {status}
        </div>
      </header>

      {currentCall && (
        <div className="call-banner">
          <div className="call-info">
            <span className="call-icon">ğŸ“</span>
            <span>{currentCall.name}ë‹˜ í†µí™”ì¤‘</span>
            <span className="call-duration">{formatDuration(callDuration)}</span>
          </div>
          <button className="end-call-btn" onClick={endCall}>ì¢…ë£Œ</button>
        </div>
      )}

      {isVoiceMode && !currentCall && (
        <div className="voice-banner">
          <div className="voice-info">
            <span className="voice-icon">ğŸ™ï¸</span>
            <span>AI ì§€ë‹ˆì™€ ëŒ€í™”ì¤‘</span>
          </div>
          <button className="stop-voice-btn" onClick={stopVoiceMode}>ì¢…ë£Œ</button>
        </div>
      )}

      <div className="chat-area" ref={chatAreaRef}>
        {messages.length === 0 ? (
          <div className="welcome-message">
            <div className="welcome-icon">ğŸ§</div>
            <h2>ì•ˆë…•í•˜ì„¸ìš”, ì§€ë‹ˆì…ë‹ˆë‹¤!</h2>
            <p>ğŸ™ï¸ ë²„íŠ¼ ëˆ„ë¥´ê³  ììœ ë¡­ê²Œ ë§ì”€í•˜ì„¸ìš”.</p>
            <p className="welcome-hint">"ì‚ì‚" ì†Œë¦¬ ë‚˜ë©´ ë§ì”€í•˜ì„¸ìš”</p>
          </div>
        ) : (
          messages.map((msg) => (
            <div key={msg.id} className={`message ${msg.isUser ? 'user' : 'ai'}`}>
              <div className="message-content">
                <p>{msg.text}</p>
                <span className="message-time">{msg.time}</span>
              </div>
            </div>
          ))
        )}
      </div>

      <div className="quick-actions">
        <button onClick={() => {
          if (!isVoiceMode) startVoiceMode();
        }}>ğŸ§ ì§€ë‹ˆì•¼</button>
        <button disabled={!currentCall} onClick={endCall}>ğŸ“´ í†µí™”ì¢…ë£Œ</button>
      </div>

      <div className="input-area">
        <button 
          className={`voice-btn ${isVoiceMode ? 'active' : ''}`}
          onClick={isVoiceMode ? stopVoiceMode : startVoiceMode}
        >
          {isVoiceMode ? 'ğŸ”´' : 'ğŸ™ï¸'}
        </button>
        <input
          type="text"
          placeholder="í…ìŠ¤íŠ¸ë¡œ ì…ë ¥..."
          value={inputText}
          onChange={(e) => setInputText(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && handleSend()}
          disabled={isVoiceMode}
        />
        <button className="send-btn" onClick={handleSend} disabled={isVoiceMode}>â¤</button>
      </div>
    </div>
  );
}

export default AgentPage;
