import { useState, useRef, useEffect } from 'react';
import './AgentPage.css';

function AgentPage({ user }) {
  const [isActive, setIsActive] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [status, setStatus] = useState('ëŒ€ê¸° ì¤‘');
  const [logs, setLogs] = useState([]);
  
  const wsRef = useRef(null);
  const audioContextRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const playbackContextRef = useRef(null);

  const addLog = (message, type = 'info') => {
    const timestamp = new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit', second: '2-digit' });
    setLogs(prev => [...prev.slice(-50), { message, type, timestamp }]);
  };

  const startAgent = async () => {
    try {
      setStatus('ë§ˆì´í¬ ì—°ê²° ì¤‘...');
      addLog('ì—ì´ì „íŠ¸ ì‹œì‘...', 'info');

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: { sampleRate: 24000, channelCount: 1, echoCancellation: true, noiseSuppression: true }
      });
      mediaStreamRef.current = stream;
      addLog('ë§ˆì´í¬ ì—°ê²°ë¨', 'success');

      setStatus('ì„œë²„ ì—°ê²° ì¤‘...');
      const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;
      
      const ws = new WebSocket(
        'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01',
        ['realtime', `openai-insecure-api-key.${OPENAI_API_KEY}`, 'openai-beta.realtime-v1']
      );

      ws.onopen = () => {
        setIsConnected(true);
        setStatus('ì„¤ì • ì¤‘...');
        addLog('OpenAI ì—°ê²° ì„±ê³µ', 'success');

        ws.send(JSON.stringify({
          type: 'session.update',
          session: {
            modalities: ['text', 'audio'],
            instructions: `ë‹¹ì‹ ì€ ARK ì§€ë‹ˆì…ë‹ˆë‹¤. ${user?.displayName || 'ë³´í—˜ì„¤ê³„ì‚¬'}ë‹˜ì„ ë•ëŠ” AI ìŒì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ í•œêµ­ì–´ë¡œ ì§§ê²Œ ì‘ë‹µí•˜ì„¸ìš”.`,
            voice: 'shimmer',
            input_audio_format: 'pcm16',
            output_audio_format: 'pcm16',
            input_audio_transcription: { model: 'whisper-1' },
            turn_detection: {
              type: 'server_vad',
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 1500
            }
          }
        }));
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleServerEvent(data);
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
        addLog('ì—°ê²° ì˜¤ë¥˜', 'error');
        setStatus('ì˜¤ë¥˜ ë°œìƒ');
      };

      ws.onclose = () => {
        setIsConnected(false);
        setIsActive(false);
        setStatus('ì—°ê²° ì¢…ë£Œ');
        addLog('ì—°ê²° ì¢…ë£Œë¨', 'info');
      };

      wsRef.current = ws;
      setIsActive(true);

    } catch (error) {
      console.error('Start error:', error);
      addLog(`ì˜¤ë¥˜: ${error.message}`, 'error');
      setStatus('ì‹œì‘ ì‹¤íŒ¨');
    }
  };

  const stopAgent = () => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    if (playbackContextRef.current) {
      playbackContextRef.current.close();
      playbackContextRef.current = null;
    }
    setIsActive(false);
    setIsConnected(false);
    setIsListening(false);
    setIsSpeaking(false);
    setStatus('ëŒ€ê¸° ì¤‘');
    addLog('ì—ì´ì „íŠ¸ ì¢…ë£Œ', 'info');
  };

  const handleServerEvent = async (data) => {
    console.log('ì„œë²„ ì´ë²¤íŠ¸:', data.type);
    
    switch (data.type) {
      case 'session.created':
        addLog('ì„¸ì…˜ ìƒì„±ë¨', 'success');
        break;

      case 'session.updated':
        setStatus('ì¤€ë¹„ ì™„ë£Œ - ë§ì”€í•˜ì„¸ìš”!');
        addLog('ì„¤ì • ì™„ë£Œ!', 'success');
        startAudioCapture();
        break;

      case 'input_audio_buffer.speech_started':
        setIsListening(true);
        setIsSpeaking(false);
        setStatus('ğŸ¤ ë“£ëŠ” ì¤‘...');
        addLog('ìŒì„± ê°ì§€ë¨', 'info');
        break;

      case 'input_audio_buffer.speech_stopped':
        setIsListening(false);
        setStatus('ğŸ”„ ì²˜ë¦¬ ì¤‘...');
        addLog('ìŒì„± ì¢…ë£Œ - ì²˜ë¦¬ ì‹œì‘', 'info');
        break;

      case 'conversation.item.input_audio_transcription.completed':
        if (data.transcript) {
          addLog(`ğŸ—£ï¸ "${data.transcript}"`, 'user');
          setStatus(`ì¸ì‹: ${data.transcript}`);
        }
        break;

      case 'response.created':
        addLog('ì‘ë‹µ ìƒì„± ì‹œì‘', 'info');
        break;

      case 'response.audio_transcript.delta':
        if (data.delta) {
          console.log('ì‘ë‹µ í…ìŠ¤íŠ¸:', data.delta);
        }
        break;

      case 'response.audio_transcript.done':
        if (data.transcript) {
          addLog(`ğŸ§ "${data.transcript}"`, 'assistant');
        }
        break;

      case 'response.audio.delta':
        setIsSpeaking(true);
        setStatus('ğŸ”Š ë§í•˜ëŠ” ì¤‘...');
        playAudio(data.delta);
        break;

      case 'response.audio.done':
        setTimeout(() => {
          setIsSpeaking(false);
          setStatus('ì¤€ë¹„ ì™„ë£Œ - ë§ì”€í•˜ì„¸ìš”!');
        }, 500);
        break;

      case 'response.done':
        addLog('ì‘ë‹µ ì™„ë£Œ', 'success');
        break;

      case 'error':
        const errorMsg = data.error?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
        addLog(`âŒ ì˜¤ë¥˜: ${errorMsg}`, 'error');
        setStatus(`ì˜¤ë¥˜: ${errorMsg}`);
        break;

      default:
        console.log('ê¸°íƒ€ ì´ë²¤íŠ¸:', data.type);
    }
  };

  const startAudioCapture = async () => {
    try {
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      await audioContextRef.current.resume();
      
      const source = audioContextRef.current.createMediaStreamSource(mediaStreamRef.current);
      const processor = audioContextRef.current.createScriptProcessor(4096, 1, 1);
      
      processor.onaudioprocess = (e) => {
        if (wsRef.current?.readyState === WebSocket.OPEN && !isSpeaking) {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcm16 = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
          wsRef.current.send(JSON.stringify({ type: 'input_audio_buffer.append', audio: base64 }));
        }
      };
      
      source.connect(processor);
      processor.connect(audioContextRef.current.destination);
      addLog('ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘', 'success');
      
    } catch (error) {
      console.error('Audio capture error:', error);
      addLog('ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨', 'error');
    }
  };

  const playAudio = async (base64Audio) => {
    try {
      if (!playbackContextRef.current) {
        playbackContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      }
      await playbackContextRef.current.resume();

      const binaryString = atob(base64Audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      
      const pcm16 = new Int16Array(bytes.buffer);
      const float32 = new Float32Array(pcm16.length);
      for (let i = 0; i < pcm16.length; i++) {
        float32[i] = pcm16[i] / 0x8000;
      }

      const buffer = playbackContextRef.current.createBuffer(1, float32.length, 24000);
      buffer.getChannelData(0).set(float32);
      const source = playbackContextRef.current.createBufferSource();
      source.buffer = buffer;
      source.connect(playbackContextRef.current.destination);
      source.start();
      
    } catch (error) {
      console.error('Playback error:', error);
    }
  };

  useEffect(() => {
    return () => stopAgent();
  }, []);

  return (
    <div className="agent-page">
      <div className="agent-header">
        <span className="header-icon">ğŸ¤–</span>
        <span className="header-title">AI ì—ì´ì „íŠ¸</span>
        <span className={`status-badge ${isConnected ? 'connected' : ''}`}>
          {isConnected ? 'â— ì—°ê²°ë¨' : 'â—‹ ì˜¤í”„ë¼ì¸'}
        </span>
      </div>

      <div className="agent-main">
        <div className={`agent-avatar ${isActive ? 'active' : ''} ${isSpeaking ? 'speaking' : ''} ${isListening ? 'listening' : ''}`}>
          <div className="avatar-circle">
            <span className="avatar-icon">ğŸ§</span>
          </div>
          {isActive && (
            <>
              <div className="pulse-ring"></div>
              <div className="pulse-ring delay-1"></div>
              <div className="pulse-ring delay-2"></div>
            </>
          )}
        </div>

        <div className="agent-status">{status}</div>

        <div className="agent-controls">
          {!isActive ? (
            <button className="start-btn" onClick={startAgent}>
              <span className="btn-icon">ğŸ¤</span>
              <span>ì—ì´ì „íŠ¸ ì‹œì‘</span>
            </button>
          ) : (
            <button className="stop-btn" onClick={stopAgent}>
              <span className="btn-icon">â¹ï¸</span>
              <span>ì¢…ë£Œ</span>
            </button>
          )}
        </div>
      </div>

      <div className="agent-logs">
        <div className="logs-header">
          <span>ğŸ“‹ ëŒ€í™” ë¡œê·¸</span>
          <button className="logs-clear" onClick={() => setLogs([])}>ì§€ìš°ê¸°</button>
        </div>
        <div className="logs-content">
          {logs.length === 0 ? (
            <div className="logs-empty">ëŒ€í™”ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤</div>
          ) : (
            logs.map((log, i) => (
              <div key={i} className={`log-item ${log.type}`}>
                <span className="log-time">{log.timestamp}</span>
                <span className="log-message">{log.message}</span>
              </div>
            ))
          )}
        </div>
      </div>
    </div>
  );
}

export default AgentPage;
