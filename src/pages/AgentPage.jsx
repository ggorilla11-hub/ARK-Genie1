import { useState, useRef, useEffect } from 'react';
import './AgentPage.css';

function AgentPage({ user }) {
  const [isActive, setIsActive] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [status, setStatus] = useState('ëŒ€ê¸°ì¤‘');
  const [logs, setLogs] = useState([]);
  const [messages, setMessages] = useState([]);
  const [textInput, setTextInput] = useState('');
  const [timeline, setTimeline] = useState([]);
  
  const wsRef = useRef(null);
  const audioContextRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const playbackContextRef = useRef(null);
  const messagesEndRef = useRef(null);
  const timelineRef = useRef(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  useEffect(() => {
    if (timelineRef.current) {
      timelineRef.current.scrollTop = timelineRef.current.scrollHeight;
    }
  }, [timeline]);

  const addLog = (message, type = 'info') => {
    const timestamp = new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit', second: '2-digit' });
    setLogs(prev => [...prev.slice(-50), { message, type, timestamp }]);
  };

  const addMessage = (text, isUser = false) => {
    const time = new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' });
    setMessages(prev => [...prev, { text, isUser, time }]);
  };

  const addTimeline = (text, icon = 'ğŸ“‹', statusVal = 'pending') => {
    const id = Date.now();
    setTimeline(prev => [...prev, { id, text, icon, status: statusVal }]);
    return id;
  };

  const updateTimeline = (id, newStatus) => {
    setTimeline(prev => prev.map(item => 
      item.id === id ? { ...item, status: newStatus } : item
    ));
  };

  const startAgent = async () => {
    try {
      setStatus('ë§ˆì´í¬ ì—°ê²° ì¤‘...');
      addLog('ì—ì´ì „íŠ¸ ì‹œì‘...', 'info');
      addTimeline('ì—ì´ì „íŠ¸ ì´ˆê¸°í™”', 'ğŸš€', 'loading');

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: { sampleRate: 24000, channelCount: 1, echoCancellation: true, noiseSuppression: true }
      });
      mediaStreamRef.current = stream;
      addLog('ë§ˆì´í¬ ì—°ê²°ë¨', 'success');

      setStatus('ì„œë²„ ì—°ê²° ì¤‘...');
      const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;
      
      const ws = new WebSocket(
        'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01',
        ['realtime', `openai-insecure-api-key.${OPENAI_API_KEY}`, 'openai-beta.realtime-v1']
      );

      ws.onopen = () => {
        setIsConnected(true);
        setStatus('ì„¤ì • ì¤‘...');
        addLog('OpenAI ì—°ê²° ì„±ê³µ', 'success');

        ws.send(JSON.stringify({
          type: 'session.update',
          session: {
            modalities: ['text', 'audio'],
            instructions: `ë‹¹ì‹ ì€ ARK ì§€ë‹ˆì…ë‹ˆë‹¤. ${user?.displayName || 'ë³´í—˜ì„¤ê³„ì‚¬'}ë‹˜ì„ ë•ëŠ” AI ìŒì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ í•œêµ­ì–´ë¡œ ì§§ê²Œ ì‘ë‹µí•˜ì„¸ìš”.`,
            voice: 'shimmer',
            input_audio_format: 'pcm16',
            output_audio_format: 'pcm16',
            input_audio_transcription: { model: 'whisper-1' },
            turn_detection: {
              type: 'server_vad',
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 1500
            }
          }
        }));
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleServerEvent(data);
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
        addLog('ì—°ê²° ì˜¤ë¥˜', 'error');
        setStatus('ì˜¤ë¥˜ ë°œìƒ');
      };

      ws.onclose = () => {
        setIsConnected(false);
        setIsActive(false);
        setStatus('ëŒ€ê¸°ì¤‘');
        addLog('ì—°ê²° ì¢…ë£Œë¨', 'info');
      };

      wsRef.current = ws;
      setIsActive(true);

    } catch (error) {
      console.error('Start error:', error);
      addLog(`ì˜¤ë¥˜: ${error.message}`, 'error');
      setStatus('ì‹œì‘ ì‹¤íŒ¨');
    }
  };

  const stopAgent = () => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    if (playbackContextRef.current) {
      playbackContextRef.current.close();
      playbackContextRef.current = null;
    }
    setIsActive(false);
    setIsConnected(false);
    setIsListening(false);
    setIsSpeaking(false);
    setStatus('ëŒ€ê¸°ì¤‘');
    addLog('ì—ì´ì „íŠ¸ ì¢…ë£Œ', 'info');
  };

  const handleServerEvent = async (data) => {
    console.log('ì„œë²„ ì´ë²¤íŠ¸:', data.type);
    
    switch (data.type) {
      case 'session.created':
        addLog('ì„¸ì…˜ ìƒì„±ë¨', 'success');
        break;

      case 'session.updated':
        setStatus('ì¤€ë¹„ì™„ë£Œ');
        addLog('ì„¤ì • ì™„ë£Œ!', 'success');
        addTimeline('ìŒì„± ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ', 'âœ…', 'done');
        startAudioCapture();
        break;

      case 'input_audio_buffer.speech_started':
        setIsListening(true);
        setIsSpeaking(false);
        setStatus('ë“£ëŠ”ì¤‘');
        addLog('ìŒì„± ê°ì§€ë¨', 'info');
        break;

      case 'input_audio_buffer.speech_stopped':
        setIsListening(false);
        setStatus('ì²˜ë¦¬ì¤‘');
        addLog('ìŒì„± ì¢…ë£Œ - ì²˜ë¦¬ ì‹œì‘', 'info');
        break;

      case 'conversation.item.input_audio_transcription.completed':
        if (data.transcript) {
          addLog(`ğŸ—£ï¸ "${data.transcript}"`, 'user');
          addMessage(data.transcript, true);
          addTimeline(`ìŒì„± ì¸ì‹: "${data.transcript.slice(0, 20)}..."`, 'ğŸ¤', 'done');
        }
        break;

      case 'response.created':
        addLog('ì‘ë‹µ ìƒì„± ì‹œì‘', 'info');
        addTimeline('AI ì‘ë‹µ ìƒì„± ì¤‘...', 'ğŸ§ ', 'loading');
        break;

      case 'response.audio_transcript.delta':
        if (data.delta) {
          console.log('ì‘ë‹µ í…ìŠ¤íŠ¸:', data.delta);
        }
        break;

      case 'response.audio_transcript.done':
        if (data.transcript) {
          addLog(`ğŸ§ "${data.transcript}"`, 'assistant');
          addMessage(data.transcript, false);
        }
        break;

      case 'response.audio.delta':
        setIsSpeaking(true);
        setStatus('ë§í•˜ëŠ”ì¤‘');
        playAudio(data.delta);
        break;

      case 'response.audio.done':
        setTimeout(() => {
          setIsSpeaking(false);
          setStatus('ì¤€ë¹„ì™„ë£Œ');
        }, 500);
        break;

      case 'response.done':
        addLog('ì‘ë‹µ ì™„ë£Œ', 'success');
        setTimeline(prev => prev.map(item => 
          item.status === 'loading' ? { ...item, status: 'done' } : item
        ));
        break;

      case 'error':
        const errorMsg = data.error?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
        addLog(`âŒ ì˜¤ë¥˜: ${errorMsg}`, 'error');
        setStatus('ì˜¤ë¥˜ ë°œìƒ');
        addTimeline(`ì˜¤ë¥˜: ${errorMsg}`, 'âŒ', 'error');
        break;

      default:
        console.log('ê¸°íƒ€ ì´ë²¤íŠ¸:', data.type);
    }
  };

  const startAudioCapture = async () => {
    try {
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      await audioContextRef.current.resume();
      
      const source = audioContextRef.current.createMediaStreamSource(mediaStreamRef.current);
      const processor = audioContextRef.current.createScriptProcessor(4096, 1, 1);
      
      processor.onaudioprocess = (e) => {
        if (wsRef.current?.readyState === WebSocket.OPEN && !isSpeaking) {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcm16 = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
          wsRef.current.send(JSON.stringify({ type: 'input_audio_buffer.append', audio: base64 }));
        }
      };
      
      source.connect(processor);
      processor.connect(audioContextRef.current.destination);
      addLog('ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘', 'success');
      
    } catch (error) {
      console.error('Audio capture error:', error);
      addLog('ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨', 'error');
    }
  };

  const playAudio = async (base64Audio) => {
    try {
      if (!playbackContextRef.current) {
        playbackContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      }
      await playbackContextRef.current.resume();

      const binaryString = atob(base64Audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      
      const pcm16 = new Int16Array(bytes.buffer);
      const float32 = new Float32Array(pcm16.length);
      for (let i = 0; i < pcm16.length; i++) {
        float32[i] = pcm16[i] / 0x8000;
      }

      const buffer = playbackContextRef.current.createBuffer(1, float32.length, 24000);
      buffer.getChannelData(0).set(float32);
      const source = playbackContextRef.current.createBufferSource();
      source.buffer = buffer;
      source.connect(playbackContextRef.current.destination);
      source.start();
      
    } catch (error) {
      console.error('Playback error:', error);
    }
  };

  const handleTextSubmit = () => {
    if (!textInput.trim()) return;
    
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      addMessage(textInput, true);
      addTimeline(`í…ìŠ¤íŠ¸ ì „ì†¡: "${textInput.slice(0, 15)}..."`, 'ğŸ’¬', 'done');
      
      wsRef.current.send(JSON.stringify({
        type: 'conversation.item.create',
        item: {
          type: 'message',
          role: 'user',
          content: [{ type: 'input_text', text: textInput }]
        }
      }));
      wsRef.current.send(JSON.stringify({ type: 'response.create' }));
      setTextInput('');
    } else {
      addMessage(textInput, true);
      setTextInput('');
    }
  };

  useEffect(() => {
    return () => stopAgent();
  }, []);

  return (
    <div className="agent-page">
      {/* 1. í—¤ë” */}
      <div className="agent-header">
        <div className="header-avatar">
          <span className="header-avatar-fallback">ğŸ¤–</span>
        </div>
        <div className="header-info">
          <span className="header-title">AI ì§€ë‹ˆ</span>
          <span className="header-subtitle">ìŒì„± ì—ì´ì „íŠ¸</span>
        </div>
        <button 
          className={`status-badge ${isActive ? (isListening ? 'listening' : isSpeaking ? 'speaking' : 'active') : ''}`}
          onClick={isActive ? stopAgent : startAgent}
        >
          {status}
        </button>
      </div>

      {/* 2. ì‹¤ì‹œê°„ ëŒ€í™” ì•ˆë‚´ */}
      <div className="agent-guide">
        <span>â”€â”€ ì‹¤ì‹œê°„ ëŒ€í™” â”€â”€</span>
        <p className="guide-main">"ì§€ë‹ˆì•¼"ë¼ê³  ë¶ˆëŸ¬ë³´ì„¸ìš”</p>
        <p className="guide-sub">ë˜ëŠ” ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”</p>
      </div>

      {/* 3. ëŒ€í™”ì°½ - ë²„íŠ¼ ìœ„ì— ìœ„ì¹˜! */}
      <div className="chat-container">
        {messages.length === 0 ? (
          <div className="chat-empty">
            <span className="chat-empty-icon">ğŸ’¬</span>
            <p>ëŒ€í™”ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤</p>
          </div>
        ) : (
          messages.map((msg, idx) => (
            <div key={idx} className={`chat-message ${msg.isUser ? 'user' : 'assistant'}`}>
              {!msg.isUser && <div className="message-avatar">ğŸ¤–</div>}
              <div className="message-bubble">
                <p>{msg.text}</p>
                <span className="message-time">{msg.time}</span>
              </div>
            </div>
          ))
        )}
        <div ref={messagesEndRef} />
      </div>

      {/* 4. ì…ë ¥ ì˜ì—­ */}
      <div className="input-section">
        <div className="action-buttons">
          <button className="action-btn">
            <span>ğŸ“·</span>
            <span>ì´¬ì˜</span>
          </button>
          <button className="action-btn">
            <span>ğŸ“</span>
            <span>íŒŒì¼</span>
          </button>
          <button className="action-btn">
            <span>ğŸ¤</span>
            <span>ë§ˆì´í¬</span>
          </button>
          <button className={`action-btn voice-btn ${isActive ? 'active' : ''}`} onClick={isActive ? stopAgent : startAgent}>
            <span>ğŸ™ï¸</span>
            <span>ë³´ì´ìŠ¤</span>
          </button>
          <button className="action-btn record-btn">
            <span>ğŸ”´</span>
            <span>ë…¹ìŒ</span>
          </button>
        </div>

        <div className="text-input-wrapper">
          <input
            type="text"
            placeholder="ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            value={textInput}
            onChange={(e) => setTextInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleTextSubmit()}
          />
          <button className="send-btn" onClick={handleTextSubmit}>
            <span>â–¶</span>
          </button>
        </div>
      </div>

      {/* 5. íƒ€ì„ë¼ì¸ - ë§¨ ì•„ë˜ */}
      <div className="timeline-section">
        <div className="timeline-header">
          <span>ğŸ“‹ ì§€ë‹ˆ í™œë™ íƒ€ì„ë¼ì¸</span>
        </div>
        <div className="timeline-content" ref={timelineRef}>
          {timeline.length === 0 ? (
            <div className="timeline-empty">í™œë™ ê¸°ë¡ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤</div>
          ) : (
            timeline.map((item) => (
              <div key={item.id} className={`timeline-item ${item.status}`}>
                <span className="timeline-icon">{item.icon}</span>
                <span className="timeline-text">{item.text}</span>
                <span className="timeline-status">
                  {item.status === 'done' && 'âœ“'}
                  {item.status === 'loading' && <span className="loading-dot">â—</span>}
                  {item.status === 'error' && 'âœ—'}
                </span>
              </div>
            ))
          )}
        </div>
      </div>
    </div>
  );
}

export default AgentPage;
