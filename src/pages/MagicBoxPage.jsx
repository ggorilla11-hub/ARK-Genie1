import { useState, useRef, useEffect, useCallback } from 'react';
import { getAIResponse, analyzeDocument, transcribeAudio, textToSpeech } from '../services/openai';
import './MagicBoxPage.css';

function MagicBoxPage({ user }) {
  // ìƒíƒœ ê´€ë¦¬
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [loading, setLoading] = useState(false);
  const [persona, setPersona] = useState('genie');
  
  // ìŒì„± ê´€ë ¨ ìƒíƒœ
  const [isMicMode, setIsMicMode] = useState(false);
  const [isVoiceMode, setIsVoiceMode] = useState(false);
  const [isRecordingConsult, setIsRecordingConsult] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  // íŒŒì¼ ê´€ë ¨ ìƒíƒœ
  const [uploadedFiles, setUploadedFiles] = useState([]);
  
  // Refs
  const fileInputRef = useRef(null);
  const cameraInputRef = useRef(null);
  const chatAreaRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const consultRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const consultChunksRef = useRef([]);
  const currentAudioRef = useRef(null);
  const silenceTimerRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);

  // ë¡œì»¬ ì €ì¥ì†Œì—ì„œ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
  useEffect(() => {
    const savedMessages = localStorage.getItem('arkgenie_messages');
    const savedTime = localStorage.getItem('arkgenie_messages_time');
    
    if (savedMessages && savedTime) {
      const timeDiff = Date.now() - parseInt(savedTime);
      const hours24 = 24 * 60 * 60 * 1000;
      
      if (timeDiff < hours24) {
        try {
          const parsed = JSON.parse(savedMessages);
          setMessages(parsed.map(m => ({ ...m, timestamp: new Date(m.timestamp) })));
          return;
        } catch (e) {
          console.error('Failed to parse saved messages');
        }
      }
    }
    
    showGreeting();
  }, []);

  // ëŒ€í™” ì €ì¥
  useEffect(() => {
    if (messages.length > 0) {
      localStorage.setItem('arkgenie_messages', JSON.stringify(messages));
      localStorage.setItem('arkgenie_messages_time', Date.now().toString());
    }
  }, [messages]);

  // ìŠ¤í¬ë¡¤ ìë™ ì´ë™
  useEffect(() => {
    if (chatAreaRef.current) {
      chatAreaRef.current.scrollTop = chatAreaRef.current.scrollHeight;
    }
  }, [messages]);

  const showGreeting = () => {
    const greeting = persona === 'genie' 
      ? `ì•ˆë…•í•˜ì„¸ìš”, ${user?.displayName || 'ì„¤ê³„ì‚¬'}ë‹˜! ğŸ‘‹\n\nì €ëŠ” ARK ì§€ë‹ˆì…ë‹ˆë‹¤.\n\nğŸ“· ì´¬ì˜ - ì„œë¥˜ ì´¬ì˜ ë¶„ì„\nğŸ“ íŒŒì¼ - ë¬¸ì„œ ì²¨ë¶€\nğŸ¤ ë§ˆì´í¬ - ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸\nğŸ”Š ë³´ì´ìŠ¤ - ì–‘ë°©í–¥ ìŒì„±ëŒ€í™”\nâºï¸ ë…¹ìŒ - ìƒë‹´ ë…¹ìŒ ìš”ì•½\n\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?`
      : `${user?.displayName || 'ì„¤ê³„ì‚¬'}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!\n\nì˜¤ìƒì—´ êµìˆ˜ì…ë‹ˆë‹¤.\nì˜¤ëŠ˜ë„ MDRTë¥¼ í–¥í•œ ì—¬ì •ì„ í•¨ê»˜ í•˜ê² ìŠµë‹ˆë‹¤.\n\në¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!`;
    
    setMessages([{ role: 'assistant', content: greeting, timestamp: new Date() }]);
  };

  useEffect(() => {
    if (messages.length <= 1) {
      showGreeting();
    }
  }, [persona]);

  const fileToBase64 = (file) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result.split(',')[1]);
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });
  };

  const addMessage = (role, content, extras = {}) => {
    const newMessage = { role, content, timestamp: new Date(), ...extras };
    setMessages(prev => [...prev, newMessage]);
    return newMessage;
  };

  const shouldShowPDF = (userMsg, aiResponse) => {
    const pdfKeywords = ['ì œì•ˆì„œ', 'PDF', 'pdf', 'ë³´ê³ ì„œ', 'ë¬¸ì„œë¡œ', 'ì €ì¥í•´', 'ë§Œë“¤ì–´ì¤˜', 'ì‘ì„±í•´ì¤˜', 'ì¶œë ¥', 'ë‹¤ìš´ë¡œë“œ'];
    const hasPdfRequest = pdfKeywords.some(keyword => userMsg.includes(keyword));
    return hasPdfRequest && aiResponse.length > 200;
  };

  const stopAISpeaking = useCallback(() => {
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current.currentTime = 0;
      currentAudioRef.current = null;
    }
    setIsSpeaking(false);
  }, []);

  const startSilenceDetection = useCallback((stream, onSilence) => {
    try {
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);
      analyserRef.current.fftSize = 512;
      
      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      let silenceStart = null;
      const SILENCE_THRESHOLD = 10;
      const SILENCE_DURATION = 1500;
      
      const checkSilence = () => {
        if (!analyserRef.current) return;
        
        analyserRef.current.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
        
        if (average < SILENCE_THRESHOLD) {
          if (!silenceStart) {
            silenceStart = Date.now();
          } else if (Date.now() - silenceStart > SILENCE_DURATION) {
            onSilence();
            return;
          }
        } else {
          silenceStart = null;
        }
        
        silenceTimerRef.current = requestAnimationFrame(checkSilence);
      };
      
      checkSilence();
    } catch (e) {
      console.error('Silence detection error:', e);
    }
  }, []);

  const stopSilenceDetection = useCallback(() => {
    if (silenceTimerRef.current) {
      cancelAnimationFrame(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    analyserRef.current = null;
  }, []);

  const handleSendMessage = async (text = inputText, options = {}) => {
    const { fromVoice = false, fromMic = false } = options;
    
    if (!text.trim() && uploadedFiles.length === 0) return;
    if (loading) return;

    const userMessage = {
      role: 'user',
      content: text || 'ì„œë¥˜ ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤',
      timestamp: new Date(),
      files: uploadedFiles.length > 0 ? [...uploadedFiles] : null
    };

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    const filesToProcess = [...uploadedFiles];
    setUploadedFiles([]);
    setLoading(true);

    try {
      let response;
      
      if (filesToProcess.length > 0 && filesToProcess.some(f => f.type.startsWith('image/'))) {
        const imageFile = filesToProcess.find(f => f.type.startsWith('image/'));
        const base64 = await fileToBase64(imageFile.file);
        response = await analyzeDocument(base64);
      } else {
        const history = messages.slice(-10).map(msg => ({ role: msg.role, content: msg.content }));
        response = await getAIResponse(text, history, persona);
      }

      const showPdf = shouldShowPDF(text, response);
      addMessage('assistant', response, { canDownload: showPdf });

      if (fromVoice && isVoiceMode) {
        await speakResponse(response);
      }
    } catch (error) {
      console.error('API Error:', error);
      addMessage('assistant', 'ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setLoading(false);
      
      if (fromVoice && isVoiceMode && !isSpeaking) {
        setTimeout(() => startVoiceListening(), 500);
      }
    }
  };

  const speakResponse = async (text) => {
    if (!text || !isVoiceMode) return;
    
    setIsSpeaking(true);
    
    try {
      const sentences = text.match(/[^.!?ã€‚]+[.!?ã€‚]?/g) || [text];
      
      for (const sentence of sentences) {
        if (!isVoiceMode || isListening) {
          stopAISpeaking();
          break;
        }
        
        const trimmed = sentence.trim();
        if (trimmed.length < 2) continue;
        
        try {
          const audioUrl = await textToSpeech(trimmed.substring(0, 500));
          
          if (!isVoiceMode || isListening) {
            stopAISpeaking();
            break;
          }
          
          await new Promise((resolve, reject) => {
            const audio = new Audio(audioUrl);
            currentAudioRef.current = audio;
            
            audio.onended = resolve;
            audio.onerror = reject;
            
            audio.play().catch(reject);
          });
        } catch (e) {
          console.error('TTS sentence error:', e);
        }
      }
    } catch (error) {
      console.error('TTS Error:', error);
    } finally {
      setIsSpeaking(false);
      currentAudioRef.current = null;
    }
  };
  // ========== ë§ˆì´í¬ ëª¨ë“œ ==========
  const handleMicMode = async () => {
    if (isMicMode) {
      stopMicRecording();
      return;
    }

    if (isVoiceMode) {
      setIsVoiceMode(false);
      stopAISpeaking();
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        stopSilenceDetection();
        
        if (audioChunksRef.current.length === 0) {
          setIsMicMode(false);
          return;
        }
        
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        
        if (audioBlob.size < 1000) {
          setIsMicMode(false);
          return;
        }
        
        setLoading(true);
        try {
          const text = await transcribeAudio(audioBlob);
          if (text && text.trim()) {
            await handleSendMessage(text, { fromMic: true });
          }
        } catch (error) {
          console.error('Transcription error:', error);
          addMessage('assistant', 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        }
        setLoading(false);
        setIsMicMode(false);
      };

      startSilenceDetection(stream, () => {
        stopMicRecording();
      });

      mediaRecorder.start();
      setIsMicMode(true);
    } catch (error) {
      console.error('Mic error:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  const stopMicRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    stopSilenceDetection();
  };

  // ========== ë³´ì´ìŠ¤ ëª¨ë“œ ==========
  const handleVoiceMode = () => {
    if (isVoiceMode) {
      setIsVoiceMode(false);
      setIsListening(false);
      stopAISpeaking();
      stopVoiceRecording();
      return;
    }

    if (isMicMode) {
      setIsMicMode(false);
      stopMicRecording();
    }

    setIsVoiceMode(true);
    addMessage('assistant', 'ğŸ”Š ë³´ì´ìŠ¤ ëª¨ë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në§ì”€í•˜ì‹œë©´ ì œê°€ ìŒì„±ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.\nëŒ€í™” ì¤‘ ë§ì”€í•˜ì‹œë©´ ì œê°€ ë©ˆì¶”ê³  ë“¤ì„ê²Œìš”.');
    
    setTimeout(() => startVoiceListening(), 500);
  };

  const startVoiceListening = async () => {
    if (!isVoiceMode || isListening || isSpeaking) return;
    
    stopAISpeaking();
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        stopSilenceDetection();
        setIsListening(false);
        
        if (!isVoiceMode) return;
        
        if (audioChunksRef.current.length === 0) {
          setTimeout(() => startVoiceListening(), 500);
          return;
        }
        
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        
        if (audioBlob.size < 1000) {
          setTimeout(() => startVoiceListening(), 500);
          return;
        }
        
        setLoading(true);
        try {
          const text = await transcribeAudio(audioBlob);
          if (text && text.trim()) {
            await handleSendMessage(text, { fromVoice: true });
          } else {
            setTimeout(() => startVoiceListening(), 500);
          }
        } catch (error) {
          console.error('Voice transcription error:', error);
          setTimeout(() => startVoiceListening(), 500);
        }
        setLoading(false);
      };

      startSilenceDetection(stream, () => {
        stopVoiceRecording();
      });

      mediaRecorder.start();
      setIsListening(true);
    } catch (error) {
      console.error('Voice listening error:', error);
      setIsListening(false);
    }
  };

  const stopVoiceRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    stopSilenceDetection();
  };

  useEffect(() => {
    if (isListening && isSpeaking) {
      stopAISpeaking();
    }
  }, [isListening, isSpeaking, stopAISpeaking]);

  // ========== ë…¹ìŒ ëª¨ë“œ ==========
  const handleRecordConsult = async () => {
    if (isRecordingConsult) {
      if (consultRecorderRef.current && consultRecorderRef.current.state === 'recording') {
        consultRecorderRef.current.stop();
      }
      return;
    }

    if (isVoiceMode) {
      setIsVoiceMode(false);
      stopAISpeaking();
      stopVoiceRecording();
    }
    if (isMicMode) {
      setIsMicMode(false);
      stopMicRecording();
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      consultRecorderRef.current = mediaRecorder;
      consultChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          consultChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        setIsRecordingConsult(false);
        
        if (consultChunksRef.current.length === 0) return;
        
        const audioBlob = new Blob(consultChunksRef.current, { type: 'audio/webm' });
        
        addMessage('user', 'ğŸ“¹ ìƒë‹´ ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìš”ì•½ì„ ìš”ì²­í•©ë‹ˆë‹¤.');
        setLoading(true);
        
        try {
          const text = await transcribeAudio(audioBlob);
          
          if (text && text.trim()) {
            const summaryPrompt = `ë‹¤ìŒì€ ë³´í—˜ì„¤ê³„ì‚¬ì™€ ê³ ê°ì˜ ìƒë‹´ ë…¹ìŒ ë‚´ìš©ì…ë‹ˆë‹¤. ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ìƒë‹´ ìš”ì•½** (3~5ì¤„)
2. **íŒŒì•…ëœ ê³ ê° ë‹ˆì¦ˆ**
3. **ì¶”ì²œ ìƒí’ˆ/ì„œë¹„ìŠ¤**
4. **ë‹¤ìŒ ìƒë‹´ ì‹œ í•  ì¼**
5. **íŠ¹ì´ì‚¬í•­**

ìƒë‹´ ë‚´ìš©:
${text}`;
            
            const response = await getAIResponse(summaryPrompt, [], persona);
            addMessage('assistant', response, { canDownload: true });
          } else {
            addMessage('assistant', 'ë…¹ìŒ ë‚´ìš©ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
          }
        } catch (error) {
          console.error('Consult recording error:', error);
          addMessage('assistant', 'ë…¹ìŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        }
        setLoading(false);
      };

      mediaRecorder.start();
      setIsRecordingConsult(true);
      addMessage('assistant', 'ğŸ”´ ìƒë‹´ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.\n\në…¹ìŒì„ ë§ˆì¹˜ì‹œë ¤ë©´ ë…¹ìŒ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.');
    } catch (error) {
      console.error('Consult record error:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  // ========== íŒŒì¼/ì¹´ë©”ë¼ ==========
  const handleCamera = () => {
    cameraInputRef.current?.click();
  };

  const handleFileSelect = () => {
    fileInputRef.current?.click();
  };

  const handleFileChange = async (e, isCamera = false) => {
    const files = Array.from(e.target.files);
    if (files.length === 0) return;

    const newFiles = files.map(file => ({
      file,
      name: file.name,
      type: file.type,
      preview: file.type.startsWith('image/') ? URL.createObjectURL(file) : null,
      isCamera
    }));

    setUploadedFiles(prev => [...prev, ...newFiles]);
    e.target.value = '';

    if (isCamera && newFiles.length > 0) {
      setTimeout(() => {
        handleSendMessage('ì´ ì„œë¥˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.');
      }, 500);
    }
  };

  const removeFile = (index) => {
    setUploadedFiles(prev => prev.filter((_, i) => i !== index));
  };

  const handleDownloadPDF = async (content) => {
    try {
      const blob = new Blob([content], { type: 'text/plain;charset=utf-8' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `ARKì§€ë‹ˆ_ë¶„ì„ê²°ê³¼_${new Date().toLocaleDateString('ko-KR').replace(/\./g, '')}.txt`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
    } catch (error) {
      console.error('Download error:', error);
      alert('ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const togglePersona = () => {
    setPersona(prev => prev === 'genie' ? 'professor' : 'genie');
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  const clearChat = () => {
    localStorage.removeItem('arkgenie_messages');
    localStorage.removeItem('arkgenie_messages_time');
    showGreeting();
  };

  // ========== ë Œë”ë§ ==========
  return (
    <div className="magicbox-page">
      <div className="magicbox-header">
        <div className="header-left">
          <span className="header-icon">ğŸ§</span>
          <span className="header-title">ë§¤ì§ë°•ìŠ¤</span>
          <span className="pro-badge">PRO</span>
        </div>
        <div className="header-right">
          <button className="clear-btn" onClick={clearChat} title="ëŒ€í™” ì´ˆê¸°í™”">ğŸ—‘ï¸</button>
          <button className="mode-toggle" onClick={togglePersona}>
            {persona === 'genie' ? 'ğŸ“ êµìˆ˜ë‹˜' : 'ğŸ§ ì§€ë‹ˆ'}
          </button>
        </div>
      </div>

      {isVoiceMode && (
        <div className="voice-mode-banner">
          <div className="voice-indicator">
            {isListening ? (
              <>
                <div className="listening-waves">
                  <span></span><span></span><span></span><span></span><span></span>
                </div>
                <span>ë“£ê³  ìˆìŠµë‹ˆë‹¤...</span>
              </>
            ) : isSpeaking ? (
              <>
                <div className="speaking-icon">ğŸ”Š</div>
                <span>ë§í•˜ëŠ” ì¤‘...</span>
              </>
            ) : loading ? (
              <>
                <div className="thinking-icon">ğŸ’­</div>
                <span>ìƒê° ì¤‘...</span>
              </>
            ) : (
              <>
                <div className="ready-icon">ğŸ¤</div>
                <span>ë§ì”€í•´ì£¼ì„¸ìš”</span>
              </>
            )}
          </div>
          <button className="voice-stop-btn" onClick={handleVoiceMode}>ì¢…ë£Œ</button>
        </div>
      )}

      {isRecordingConsult && (
        <div className="recording-banner">
          <div className="rec-indicator">
            <div className="rec-dot"></div>
            <span>ìƒë‹´ ë…¹ìŒ ì¤‘...</span>
          </div>
          <button className="rec-stop-btn" onClick={handleRecordConsult}>ë…¹ìŒ ì¢…ë£Œ</button>
        </div>
      )}

      <div className="chat-area" ref={chatAreaRef}>
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.role}`}>
            {msg.files && (
              <div className="message-files">
                {msg.files.map((file, i) => (
                  <div key={i} className="file-preview-msg">
                    {file.preview ? (
                      <img src={file.preview} alt={file.name} />
                    ) : (
                      <span className="file-icon">ğŸ“„</span>
                    )}
                  </div>
                ))}
              </div>
            )}
            <div className="message-bubble">
              {msg.content.split('\n').map((line, i) => (
                <p key={i}>{line}</p>
              ))}
            </div>
            {msg.role === 'assistant' && msg.canDownload && (
              <div className="message-actions">
                <button className="action-btn" onClick={() => handleDownloadPDF(msg.content)}>
                  ğŸ“„ ì €ì¥
                </button>
              </div>
            )}
            <div className="message-time">
              {msg.timestamp.toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })}
            </div>
          </div>
        ))}
        
        {loading && (
          <div className="message assistant">
            <div className="typing-indicator">
              <span></span><span></span><span></span>
            </div>
          </div>
        )}
      </div>

      <div className="input-area">
        {uploadedFiles.length > 0 && (
          <div className="uploaded-files">
            {uploadedFiles.map((file, index) => (
              <div key={index} className="uploaded-file">
                {file.preview ? (
                  <img src={file.preview} alt={file.name} />
                ) : (
                  <span className="file-icon">ğŸ“„</span>
                )}
                <button className="remove-file" onClick={() => removeFile(index)}>Ã—</button>
              </div>
            ))}
          </div>
        )}

        <div className="input-tools">
          <button className="tool-btn" onClick={handleCamera} title="ì¹´ë©”ë¼">
            <span className="tool-icon">ğŸ“·</span>
            <span className="tool-label">ì´¬ì˜</span>
          </button>
          <button className="tool-btn" onClick={handleFileSelect} title="íŒŒì¼ ì²¨ë¶€">
            <span className="tool-icon">ğŸ“</span>
            <span className="tool-label">íŒŒì¼</span>
          </button>
          <button 
            className={`tool-btn ${isMicMode ? 'active recording' : ''}`} 
            onClick={handleMicMode}
            title="ë§ˆì´í¬ (í…ìŠ¤íŠ¸ ë‹µë³€)"
          >
            <span className="tool-icon">ğŸ¤</span>
            <span className="tool-label">ë§ˆì´í¬</span>
          </button>
          <button 
            className={`tool-btn ${isVoiceMode ? 'active' : ''}`} 
            onClick={handleVoiceMode}
            title="ë³´ì´ìŠ¤ (ìŒì„± ëŒ€í™”)"
          >
            <span className="tool-icon">ğŸ”Š</span>
            <span className="tool-label">ë³´ì´ìŠ¤</span>
          </button>
          <button 
            className={`tool-btn ${isRecordingConsult ? 'active recording' : ''}`} 
            onClick={handleRecordConsult}
            title="ìƒë‹´ ë…¹ìŒ"
          >
            <span className="tool-icon">âºï¸</span>
            <span className="tool-label">ë…¹ìŒ</span>
          </button>
        </div>

        <div className="text-input-row">
          <input
            type="text"
            className="text-input"
            placeholder={isVoiceMode ? "ë³´ì´ìŠ¤ ëª¨ë“œ ì¤‘..." : "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
            value={inputText}
            onChange={(e) => setInputText(e.target.value)}
            onKeyPress={handleKeyPress}
            disabled={loading || isVoiceMode || isMicMode}
          />
          <button
            className="send-btn"
            onClick={() => handleSendMessage()}
            disabled={loading || isVoiceMode || isMicMode || (!inputText.trim() && uploadedFiles.length === 0)}
          >
            â¤
          </button>
        </div>

        <input
          ref={cameraInputRef}
          type="file"
          accept="image/*"
          capture="environment"
          style={{ display: 'none' }}
          onChange={(e) => handleFileChange(e, true)}
        />
        <input
          ref={fileInputRef}
          type="file"
          accept="image/*,.pdf,.doc,.docx"
          multiple
          style={{ display: 'none' }}
          onChange={(e) => handleFileChange(e, false)}
        />
      </div>
    </div>
  );
}

export default MagicBoxPage;
