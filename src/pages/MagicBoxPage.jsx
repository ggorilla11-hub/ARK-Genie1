import { useState, useRef, useEffect } from 'react';
import { getAIResponse, analyzeDocument, transcribeAudio, textToSpeech } from '../services/openai';
import { generateAnalysisReport } from '../services/pdfService';
import './MagicBoxPage.css';

function MagicBoxPage({ user }) {
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [loading, setLoading] = useState(false);
  const [persona, setPersona] = useState('genie');
  const [isVoiceMode, setIsVoiceMode] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isConsultRecording, setIsConsultRecording] = useState(false);
  const [consultChunks, setConsultChunks] = useState([]);
  const [uploadedFiles, setUploadedFiles] = useState([]);
  
  const fileInputRef = useRef(null);
  const cameraInputRef = useRef(null);
  const chatAreaRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const consultRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  useEffect(() => {
    const greeting = persona === 'genie' 
      ? `ì•ˆë…•í•˜ì„¸ìš”, ${user?.displayName || 'ì„¤ê³„ì‚¬'}ë‹˜! ðŸ‘‹\n\nì €ëŠ” ARK ì§€ë‹ˆ, ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ AI ë³´í—˜ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.\n\nðŸ“· **ì¹´ë©”ë¼**: ì¦ê¶Œ/ì„œë¥˜ ì´¬ì˜í•˜ì—¬ ì¦‰ì‹œ ë¶„ì„\nðŸ“Ž **íŒŒì¼**: ë¬¸ì„œ ì²¨ë¶€í•˜ì—¬ ë¶„ì„\nðŸŽ¤ **ë§ˆì´í¬**: ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸ (í…ìŠ¤íŠ¸ ë‹µë³€)\nðŸ”Š **ë³´ì´ìŠ¤**: ì–‘ë°©í–¥ ìŒì„± ëŒ€í™”\nâºï¸ **ë…¹ìŒ**: ìƒë‹´ ë…¹ìŒ í›„ ìš”ì•½\n\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?`
      : `ì•ˆë…•í•˜ì„¸ìš”, ${user?.displayName || 'ì„¤ê³„ì‚¬'}ë‹˜!\n\nì˜¤ìƒì—´ êµìˆ˜ìž…ë‹ˆë‹¤.\nì˜¤ëŠ˜ë„ í›Œë¥­í•œ MDRTê°€ ë˜ê¸° ìœ„í•œ ì—¬ì •ì„ í•¨ê»˜ í•˜ê² ìŠµë‹ˆë‹¤.\n\në¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!`;
    
    setMessages([{ role: 'assistant', content: greeting, timestamp: new Date() }]);
  }, [user, persona]);

  useEffect(() => {
    if (chatAreaRef.current) {
      chatAreaRef.current.scrollTop = chatAreaRef.current.scrollHeight;
    }
  }, [messages]);

  const fileToBase64 = (file) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result.split(',')[1]);
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });
  };

  const addMessage = (role, content, extras = {}) => {
    setMessages(prev => [...prev, { role, content, timestamp: new Date(), ...extras }]);
  };

  const handleSendMessage = async (text = inputText, fromVoice = false) => {
    if (!text.trim() && uploadedFiles.length === 0) return;
    if (loading) return;

    const userMessage = {
      role: 'user',
      content: text || 'ì„œë¥˜ ë¶„ì„ ìš”ì²­',
      timestamp: new Date(),
      files: uploadedFiles.length > 0 ? [...uploadedFiles] : null
    };

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    const filesToProcess = [...uploadedFiles];
    setUploadedFiles([]);
    setLoading(true);

    try {
      let response;
      
      if (filesToProcess.length > 0 && filesToProcess.some(f => f.type.startsWith('image/'))) {
        const imageFile = filesToProcess.find(f => f.type.startsWith('image/'));
        const base64 = await fileToBase64(imageFile.file);
        response = await analyzeDocument(base64);
      } else {
        const history = messages.slice(-10).map(msg => ({ role: msg.role, content: msg.content }));
        response = await getAIResponse(text, history, persona);
      }

      addMessage('assistant', response, { canDownload: response.length > 200 });

      // ë³´ì´ìŠ¤ ëª¨ë“œë©´ AI ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ì¶œë ¥ í›„ ë‹¤ì‹œ ë“£ê¸° ì‹œìž‘
      if (isVoiceMode || fromVoice) {
        try {
          const audioUrl = await textToSpeech(response.substring(0, 1000));
          const audio = new Audio(audioUrl);
          audio.onended = () => {
            if (isVoiceMode) startVoiceListening();
          };
          audio.play();
        } catch (e) {
          console.error('TTS Error:', e);
          if (isVoiceMode) startVoiceListening();
        }
      }
    } catch (error) {
      addMessage('assistant', 'ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setLoading(false);
    }
  };

  // ì¹´ë©”ë¼ ì´¬ì˜ (ì‹¤ì œ ì¹´ë©”ë¼)
  const handleCamera = () => {
    cameraInputRef.current?.click();
  };

  // íŒŒì¼ ì„ íƒ
  const handleFileSelect = () => {
    fileInputRef.current?.click();
  };

  const handleFileChange = async (e, isCamera = false) => {
    const files = Array.from(e.target.files);
    if (files.length === 0) return;

    const newFiles = files.map(file => ({
      file,
      name: file.name,
      type: file.type,
      preview: file.type.startsWith('image/') ? URL.createObjectURL(file) : null,
      isCamera
    }));

    setUploadedFiles(prev => [...prev, ...newFiles]);
    e.target.value = '';

    // ì¹´ë©”ë¼ ì´¬ì˜ì´ë©´ ìžë™ìœ¼ë¡œ ë¶„ì„ ì‹œìž‘
    if (isCamera && newFiles.length > 0) {
      setTimeout(() => {
        handleSendMessage('ì´ ì„œë¥˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.');
      }, 500);
    }
  };

  const removeFile = (index) => {
    setUploadedFiles(prev => prev.filter((_, i) => i !== index));
  };

  // ë§ˆì´í¬ (ìŒì„± â†’ í…ìŠ¤íŠ¸, AIëŠ” í…ìŠ¤íŠ¸ë¡œ ë‹µë³€)
  const handleMicPress = async () => {
    if (isRecording) {
      mediaRecorderRef.current?.stop();
      setIsRecording(false);
    } else {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const mediaRecorder = new MediaRecorder(stream);
        mediaRecorderRef.current = mediaRecorder;
        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (e) => audioChunksRef.current.push(e.data);
        
        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
          stream.getTracks().forEach(track => track.stop());
          
          setLoading(true);
          try {
            const text = await transcribeAudio(audioBlob);
            if (text) {
              addMessage('user', text);
              const history = messages.slice(-10).map(msg => ({ role: msg.role, content: msg.content }));
              const response = await getAIResponse(text, history, persona);
              addMessage('assistant', response, { canDownload: response.length > 200 });
            }
          } catch (error) {
            addMessage('assistant', 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
          }
          setLoading(false);
        };

        mediaRecorder.start();
        setIsRecording(true);
      } catch (error) {
        alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      }
    }
  };

  // ë³´ì´ìŠ¤ ëª¨ë“œ (ì–‘ë°©í–¥ ìŒì„± ëŒ€í™”)
  const startVoiceListening = async () => {
    if (!isVoiceMode) return;
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRe
