import { useState, useRef, useEffect, useCallback } from 'react';
import { getAIResponse, analyzeDocument, textToSpeech } from '../services/openai';
import './MagicBoxPage.css';

function MagicBoxPage({ user }) {
  // ìƒíƒœ ê´€ë¦¬
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [loading, setLoading] = useState(false);
  const [persona, setPersona] = useState('genie');
  
  // ìŒì„± ê´€ë ¨ ìƒíƒœ
  const [isMicMode, setIsMicMode] = useState(false);
  const [isVoiceMode, setIsVoiceMode] = useState(false);
  const [isRecordingConsult, setIsRecordingConsult] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [currentTranscript, setCurrentTranscript] = useState('');
  
  // íŒŒì¼ ê´€ë ¨ ìƒíƒœ
  const [uploadedFiles, setUploadedFiles] = useState([]);
  
  // Refs
  const fileInputRef = useRef(null);
  const cameraInputRef = useRef(null);
  const chatAreaRef = useRef(null);
  const recognitionRef = useRef(null);
  const consultRecorderRef = useRef(null);
  const consultChunksRef = useRef([]);
  const currentAudioRef = useRef(null);
  const isProcessingRef = useRef(false);
  const voiceModeRef = useRef(false);
  const micModeRef = useRef(false);
  const finalTranscriptRef = useRef('');
  const silenceTimeoutRef = useRef(null);

  // ë¡œì»¬ ì €ì¥ì†Œì—ì„œ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
  useEffect(() => {
    const savedMessages = localStorage.getItem('arkgenie_messages');
    const savedTime = localStorage.getItem('arkgenie_messages_time');
    
    if (savedMessages && savedTime) {
      const timeDiff = Date.now() - parseInt(savedTime);
      const hours24 = 24 * 60 * 60 * 1000;
      
      if (timeDiff < hours24) {
        try {
          const parsed = JSON.parse(savedMessages);
          setMessages(parsed.map(m => ({ ...m, timestamp: new Date(m.timestamp) })));
          return;
        } catch (e) {
          console.error('Failed to parse saved messages');
        }
      }
    }
    
    showGreeting();
  }, []);

  // ëŒ€í™” ì €ì¥
  useEffect(() => {
    if (messages.length > 0) {
      localStorage.setItem('arkgenie_messages', JSON.stringify(messages));
      localStorage.setItem('arkgenie_messages_time', Date.now().toString());
    }
  }, [messages]);

  // ìŠ¤í¬ë¡¤ ìë™ ì´ë™
  useEffect(() => {
    if (chatAreaRef.current) {
      chatAreaRef.current.scrollTop = chatAreaRef.current.scrollHeight;
    }
  }, [messages, currentTranscript]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopAllModes();
    };
  }, []);

  const stopAllModes = () => {
    if (recognitionRef.current) {
      try { recognitionRef.current.stop(); } catch(e) {}
      recognitionRef.current = null;
    }
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current = null;
    }
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    voiceModeRef.current = false;
    micModeRef.current = false;
  };

  const showGreeting = () => {
    const greeting = persona === 'genie' 
      ? `ì•ˆë…•í•˜ì„¸ìš”, ${user?.displayName || 'ì„¤ê³„ì‚¬'}ë‹˜! ğŸ‘‹\n\nì €ëŠ” ARK ì§€ë‹ˆì…ë‹ˆë‹¤.\n\nğŸ“· ì´¬ì˜ - ì„œë¥˜ ì´¬ì˜ ë¶„ì„\nğŸ“ íŒŒì¼ - ë¬¸ì„œ ì²¨ë¶€\nğŸ¤ ë§ˆì´í¬ - ìŒì„± ì§ˆë¬¸ (í…ìŠ¤íŠ¸ ë‹µë³€)\nğŸ”Š ë³´ì´ìŠ¤ - ì–‘ë°©í–¥ ìŒì„±ëŒ€í™”\nâºï¸ ë…¹ìŒ - ìƒë‹´ ë…¹ìŒ ìš”ì•½\n\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?`
      : `${user?.displayName || 'ì„¤ê³„ì‚¬'}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!\n\nì˜¤ìƒì—´ êµìˆ˜ì…ë‹ˆë‹¤.\nì˜¤ëŠ˜ë„ MDRTë¥¼ í–¥í•œ ì—¬ì •ì„ í•¨ê»˜ í•˜ê² ìŠµë‹ˆë‹¤.\n\në¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!`;
    
    setMessages([{ role: 'assistant', content: greeting, timestamp: new Date() }]);
  };

  useEffect(() => {
    if (messages.length <= 1) {
      showGreeting();
    }
  }, [persona]);

  const fileToBase64 = (file) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result.split(',')[1]);
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });
  };

  const addMessage = (role, content, extras = {}) => {
    const newMessage = { role, content, timestamp: new Date(), ...extras };
    setMessages(prev => [...prev, newMessage]);
    return newMessage;
  };

  const shouldShowPDF = (userMsg, aiResponse) => {
    const pdfKeywords = ['ì œì•ˆì„œ', 'PDF', 'pdf', 'ë³´ê³ ì„œ', 'ë¬¸ì„œë¡œ', 'ì €ì¥í•´', 'ë§Œë“¤ì–´ì¤˜', 'ì‘ì„±í•´ì¤˜', 'ì¶œë ¥', 'ë‹¤ìš´ë¡œë“œ'];
    const hasPdfRequest = pdfKeywords.some(keyword => userMsg.includes(keyword));
    return hasPdfRequest && aiResponse.length > 200;
  };

  // AI ìŒì„± ì¦‰ì‹œ ì¤‘ë‹¨
  const stopAISpeaking = useCallback(() => {
    console.log('AI ìŒì„± ì¤‘ë‹¨');
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current.currentTime = 0;
      currentAudioRef.current = null;
    }
    setIsSpeaking(false);
  }, []);

  // AI ìŒì„± ì¶œë ¥ (ë³´ì´ìŠ¤ ëª¨ë“œ ì „ìš©)
  const speakText = async (text) => {
    if (!text || !voiceModeRef.current) {
      console.log('TTS ìŠ¤í‚µ: voiceMode=', voiceModeRef.current);
      return;
    }
    
    console.log('TTS ì‹œì‘ ìš”ì²­:', text.substring(0, 30));
    setIsSpeaking(true);
    
    try {
      const audioUrl = await textToSpeech(text);
      console.log('TTS URL ë°›ìŒ:', audioUrl);
      
      if (!voiceModeRef.current) {
        console.log('TTS ì·¨ì†Œ: ë³´ì´ìŠ¤ ëª¨ë“œ ì¢…ë£Œë¨');
        setIsSpeaking(false);
        return;
      }
      
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;
      
      audio.onplay = () => {
        console.log('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘');
      };
      
      audio.onended = () => {
        console.log('ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ');
        currentAudioRef.current = null;
        setIsSpeaking(false);
        
        // ë³´ì´ìŠ¤ ëª¨ë“œë©´ ë‹¤ì‹œ ë“£ê¸°
        if (voiceModeRef.current) {
          setTimeout(() => {
            startListening('voice');
          }, 500);
        }
      };
      
      audio.onerror = (e) => {
        console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', e);
        currentAudioRef.current = null;
        setIsSpeaking(false);
        
        if (voiceModeRef.current) {
          setTimeout(() => {
            startListening('voice');
          }, 500);
        }
      };
      
      await audio.play();
      console.log('audio.play() í˜¸ì¶œ ì„±ê³µ');
      
    } catch (error) {
      console.error('TTS ì˜¤ë¥˜:', error);
      setIsSpeaking(false);
      
      if (voiceModeRef.current) {
        setTimeout(() => {
          startListening('voice');
        }, 500);
      }
    }
  };

  // ë©”ì‹œì§€ ì²˜ë¦¬
  const processMessage = async (text, mode) => {
    if (!text || !text.trim() || isProcessingRef.current) {
      console.log('ë©”ì‹œì§€ ì²˜ë¦¬ ìŠ¤í‚µ');
      return;
    }
    
    console.log('ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘:', text, 'ëª¨ë“œ:', mode);
    isProcessingRef.current = true;

    const userMessage = {
      role: 'user',
      content: text.trim(),
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setLoading(true);

    try {
      const history = messages.slice(-10).map(msg => ({ role: msg.role, content: msg.content }));
      const response = await getAIResponse(text, history, persona);
      const showPdf = shouldShowPDF(text, response);
      addMessage('assistant', response, { canDownload: showPdf });
      
      // ë³´ì´ìŠ¤ ëª¨ë“œë©´ ìŒì„± ì¶œë ¥
      if (mode === 'voice' && voiceModeRef.current) {
        console.log('ë³´ì´ìŠ¤ ëª¨ë“œ - TTS í˜¸ì¶œ');
        await speakText(response);
      } else if (mode === 'mic' && micModeRef.current) {
        // ë§ˆì´í¬ ëª¨ë“œë©´ ë‹¤ì‹œ ë“£ê¸°
        setTimeout(() => {
          startListening('mic');
        }, 500);
      }
    } catch (error) {
      console.error('API Error:', error);
      addMessage('assistant', 'ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      
      // ì—ëŸ¬ ë‚˜ë„ ë‹¤ì‹œ ë“£ê¸°
      if (mode === 'voice' && voiceModeRef.current) {
        setTimeout(() => startListening('voice'), 500);
      } else if (mode === 'mic' && micModeRef.current) {
        setTimeout(() => startListening('mic'), 500);
      }
    } finally {
      setLoading(false);
      isProcessingRef.current = false;
    }
  };

  // ì¼ë°˜ í…ìŠ¤íŠ¸/íŒŒì¼ ì „ì†¡
  const handleSendMessage = async (text) => {
    if (!text || !text.trim()) return;
    if (isProcessingRef.current) return;
    
    isProcessingRef.current = true;

    const userMessage = {
      role: 'user',
      content: text,
      timestamp: new Date(),
      files: uploadedFiles.length > 0 ? [...uploadedFiles] : null
    };

    setMessages(prev => [...prev, userMessage]);
    const filesToProcess = [...uploadedFiles];
    setUploadedFiles([]);
    setLoading(true);

    try {
      let response;
      
      if (filesToProcess.length > 0 && filesToProcess.some(f => f.type.startsWith('image/'))) {
        const imageFile = filesToProcess.find(f => f.type.startsWith('image/'));
        const base64 = await fileToBase64(imageFile.file);
        response = await analyzeDocument(base64);
      } else {
        const history = messages.slice(-10).map(msg => ({ role: msg.role, content: msg.content }));
        response = await getAIResponse(text, history, persona);
      }

      const showPdf = shouldShowPDF(text, response);
      addMessage('assistant', response, { canDownload: showPdf });
    } catch (error) {
      console.error('API Error:', error);
      addMessage('assistant', 'ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setLoading(false);
      isProcessingRef.current = false;
    }
  };

  // ========== ìŒì„± ì¸ì‹ ì‹œì‘ ==========
  const startListening = (mode) => {
    console.log('ë“£ê¸° ì‹œì‘:', mode);
    
    if (isProcessingRef.current || isSpeaking) {
      console.log('ë“£ê¸° ìŠ¤í‚µ - ì²˜ë¦¬ì¤‘ ë˜ëŠ” ë§í•˜ëŠ”ì¤‘');
      return;
    }

    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chromeì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
      return;
    }

    // ê¸°ì¡´ ì¸ì‹ ì¤‘ì§€
    if (recognitionRef.current) {
      try { recognitionRef.current.stop(); } catch(e) {}
      recognitionRef.current = null;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.lang = 'ko-KR';
    recognition.continuous = false;  // í•œ ë¬¸ì¥ì”© ì²˜ë¦¬
    recognition.interimResults = true;
    recognition.maxAlternatives = 1;

    recognitionRef.current = recognition;
    finalTranscriptRef.current = '';
    
    recognition.onstart = () => {
      console.log('ìŒì„± ì¸ì‹ ì‹œì‘');
      setIsListening(true);
      setCurrentTranscript('');
    };

    recognition.onresult = (event) => {
      let interim = '';
      let final = '';
      
      for (let i = 0; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          final += transcript;
        } else {
          interim += transcript;
        }
      }
      
      // ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ
      setCurrentTranscript(interim || final);
      
      if (final) {
        finalTranscriptRef.current = final;
        console.log('ìµœì¢… ì¸ì‹:', final);
      }
    };

    recognition.onerror = (event) => {
      console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      
      if (event.error === 'no-speech') {
        // ë§ì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ì‹œì‘
        if ((mode === 'voice' && voiceModeRef.current) || (mode === 'mic' && micModeRef.current)) {
          setTimeout(() => {
            if ((mode === 'voice' && voiceModeRef.current) || (mode === 'mic' && micModeRef.current)) {
              startListening(mode);
            }
          }, 300);
        }
      }
    };

    recognition.onend = () => {
      console.log('ìŒì„± ì¸ì‹ ì¢…ë£Œ, ìµœì¢…:', finalTranscriptRef.current);
      setIsListening(false);
      setCurrentTranscript('');
      
      const finalText = finalTranscriptRef.current.trim();
      
      if (finalText) {
        // ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
        processMessage(finalText, mode);
      } else {
        // ì—†ìœ¼ë©´ ë‹¤ì‹œ ë“£ê¸°
        if ((mode === 'voice' && voiceModeRef.current) || (mode === 'mic' && micModeRef.current)) {
          setTimeout(() => {
            if ((mode === 'voice' && voiceModeRef.current && !isSpeaking) || 
                (mode === 'mic' && micModeRef.current)) {
              startListening(mode);
            }
          }, 300);
        }
      }
    };

    try {
      recognition.start();
    } catch (e) {
      console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', e);
    }
  };
  // ========== ë§ˆì´í¬ ëª¨ë“œ ==========
  const handleMicMode = () => {
    if (isMicMode) {
      micModeRef.current = false;
      setIsMicMode(false);
      setIsListening(false);
      setCurrentTranscript('');
      if (recognitionRef.current) {
        try { recognitionRef.current.stop(); } catch(e) {}
        recognitionRef.current = null;
      }
      return;
    }

    if (isVoiceMode) {
      voiceModeRef.current = false;
      setIsVoiceMode(false);
      stopAISpeaking();
    }

    micModeRef.current = true;
    setIsMicMode(true);
    addMessage('assistant', 'ğŸ¤ ë§ˆì´í¬ ëª¨ë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në§ì”€í•˜ì‹œë©´ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.\në§ˆì´í¬ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.');
    
    setTimeout(() => {
      startListening('mic');
    }, 500);
  };

  // ========== ë³´ì´ìŠ¤ ëª¨ë“œ ==========
  const handleVoiceMode = () => {
    if (isVoiceMode) {
      console.log('ë³´ì´ìŠ¤ ëª¨ë“œ ì¢…ë£Œ');
      voiceModeRef.current = false;
      setIsVoiceMode(false);
      setIsListening(false);
      setCurrentTranscript('');
      stopAISpeaking();
      if (recognitionRef.current) {
        try { recognitionRef.current.stop(); } catch(e) {}
        recognitionRef.current = null;
      }
      return;
    }

    if (isMicMode) {
      micModeRef.current = false;
      setIsMicMode(false);
    }

    console.log('ë³´ì´ìŠ¤ ëª¨ë“œ ì‹œì‘');
    voiceModeRef.current = true;
    setIsVoiceMode(true);
    addMessage('assistant', 'ğŸ”Š ë³´ì´ìŠ¤ ëª¨ë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në§ì”€í•˜ì‹œë©´ ìŒì„±ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.\nì œê°€ ë§í•˜ëŠ” ì¤‘ì— ë§ì”€í•˜ì‹œë©´ ë©ˆì¶”ê³  ë“¤ì„ê²Œìš”.\në³´ì´ìŠ¤ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.');
    
    setTimeout(() => {
      startListening('voice');
    }, 500);
  };

  // ========== ë…¹ìŒ ëª¨ë“œ ==========
  const handleRecordConsult = async () => {
    if (isRecordingConsult) {
      if (consultRecorderRef.current && consultRecorderRef.current.state === 'recording') {
        consultRecorderRef.current.stop();
      }
      return;
    }

    if (isVoiceMode) {
      voiceModeRef.current = false;
      setIsVoiceMode(false);
      stopAISpeaking();
    }
    if (isMicMode) {
      micModeRef.current = false;
      setIsMicMode(false);
    }
    if (recognitionRef.current) {
      try { recognitionRef.current.stop(); } catch(e) {}
      recognitionRef.current = null;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      consultRecorderRef.current = mediaRecorder;
      consultChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          consultChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        setIsRecordingConsult(false);
        
        if (consultChunksRef.current.length === 0) return;
        
        const audioBlob = new Blob(consultChunksRef.current, { type: 'audio/webm' });
        
        addMessage('user', 'ğŸ“¹ ìƒë‹´ ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìš”ì•½ì„ ìš”ì²­í•©ë‹ˆë‹¤.');
        setLoading(true);
        
        try {
          // Whisper APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
          const formData = new FormData();
          formData.append('file', audioBlob, 'recording.webm');
          formData.append('model', 'whisper-1');
          formData.append('language', 'ko');
          
          const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;
          
          const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${OPENAI_API_KEY}`
            },
            body: formData
          });
          
          if (response.ok) {
            const data = await response.json();
            const text = data.text;
            
            if (text && text.trim()) {
              const summaryPrompt = `ë‹¤ìŒì€ ë³´í—˜ì„¤ê³„ì‚¬ì™€ ê³ ê°ì˜ ìƒë‹´ ë…¹ìŒ ë‚´ìš©ì…ë‹ˆë‹¤. ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ìƒë‹´ ìš”ì•½** (3~5ì¤„)
2. **íŒŒì•…ëœ ê³ ê° ë‹ˆì¦ˆ**
3. **ì¶”ì²œ ìƒí’ˆ/ì„œë¹„ìŠ¤**
4. **ë‹¤ìŒ ìƒë‹´ ì‹œ í•  ì¼**
5. **íŠ¹ì´ì‚¬í•­**

ìƒë‹´ ë‚´ìš©:
${text}`;
              
              const aiResponse = await getAIResponse(summaryPrompt, [], persona);
              addMessage('assistant', aiResponse, { canDownload: true });
            } else {
              addMessage('assistant', 'ë…¹ìŒ ë‚´ìš©ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
            }
          } else {
            throw new Error('Transcription failed');
          }
        } catch (error) {
          console.error('Consult recording error:', error);
          addMessage('assistant', 'ë…¹ìŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        }
        setLoading(false);
      };

      mediaRecorder.start();
      setIsRecordingConsult(true);
      addMessage('assistant', 'ğŸ”´ ìƒë‹´ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.\n\në…¹ìŒì„ ë§ˆì¹˜ì‹œë ¤ë©´ ë…¹ìŒ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.');
    } catch (error) {
      console.error('Consult record error:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  // ========== íŒŒì¼/ì¹´ë©”ë¼ ==========
  const handleCamera = () => {
    cameraInputRef.current?.click();
  };

  const handleFileSelect = () => {
    fileInputRef.current?.click();
  };

  const handleFileChange = async (e, isCamera = false) => {
    const files = Array.from(e.target.files);
    if (files.length === 0) return;

    const newFiles = files.map(file => ({
      file,
      name: file.name,
      type: file.type,
      preview: file.type.startsWith('image/') ? URL.createObjectURL(file) : null,
      isCamera
    }));

    setUploadedFiles(prev => [...prev, ...newFiles]);
    e.target.value = '';

    if (isCamera && newFiles.length > 0) {
      setTimeout(() => {
        handleSendMessage('ì´ ì„œë¥˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.');
      }, 500);
    }
  };

  const removeFile = (index) => {
    setUploadedFiles(prev => prev.filter((_, i) => i !== index));
  };

  const handleDownloadFile = async (content) => {
    try {
      const BOM = '\uFEFF';
      const blob = new Blob([BOM + content], { type: 'text/plain;charset=utf-8' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `ARKì§€ë‹ˆ_ë¶„ì„ê²°ê³¼_${new Date().toLocaleDateString('ko-KR').replace(/\./g, '')}.txt`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
    } catch (error) {
      console.error('Download error:', error);
      alert('ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const handleTextSubmit = () => {
    if (!inputText.trim()) return;
    handleSendMessage(inputText);
    setInputText('');
  };

  const togglePersona = () => {
    setPersona(prev => prev === 'genie' ? 'professor' : 'genie');
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleTextSubmit();
    }
  };

  const clearChat = () => {
    localStorage.removeItem('arkgenie_messages');
    localStorage.removeItem('arkgenie_messages_time');
    showGreeting();
  };

  // ========== ë Œë”ë§ ==========
  return (
    <div className="magicbox-page">
      <div className="magicbox-header">
        <div className="header-left">
          <span className="header-icon">ğŸ§</span>
          <span className="header-title">ë§¤ì§ë°•ìŠ¤</span>
          <span className="pro-badge">PRO</span>
        </div>
        <div className="header-right">
          <button className="clear-btn" onClick={clearChat} title="ëŒ€í™” ì´ˆê¸°í™”">ğŸ—‘ï¸</button>
          <button className="mode-toggle" onClick={togglePersona}>
            {persona === 'genie' ? 'ğŸ“ êµìˆ˜ë‹˜' : 'ğŸ§ ì§€ë‹ˆ'}
          </button>
        </div>
      </div>

      {isVoiceMode && (
        <div className="voice-mode-banner">
          <div className="voice-indicator">
            {isSpeaking ? (
              <>
                <div className="speaking-icon">ğŸ”Š</div>
                <span>ë§í•˜ëŠ” ì¤‘...</span>
              </>
            ) : loading ? (
              <>
                <div className="thinking-icon">ğŸ’­</div>
                <span>ìƒê° ì¤‘...</span>
              </>
            ) : isListening ? (
              <>
                <div className="listening-waves">
                  <span></span><span></span><span></span><span></span><span></span>
                </div>
                <span>ë“£ê³  ìˆìŠµë‹ˆë‹¤...</span>
              </>
            ) : (
              <>
                <div className="ready-icon">ğŸ¤</div>
                <span>ì¤€ë¹„ ì¤‘...</span>
              </>
            )}
          </div>
          <button className="voice-stop-btn" onClick={handleVoiceMode}>ì¢…ë£Œ</button>
        </div>
      )}

      {isMicMode && (
        <div className="mic-mode-banner">
          <div className="mic-indicator">
            {loading ? (
              <>
                <div className="thinking-icon">ğŸ’­</div>
                <span>ìƒê° ì¤‘...</span>
              </>
            ) : isListening ? (
              <>
                <div className="listening-waves">
                  <span></span><span></span><span></span><span></span><span></span>
                </div>
                <span>ë“£ê³  ìˆìŠµë‹ˆë‹¤...</span>
              </>
            ) : (
              <>
                <div className="ready-icon">ğŸ¤</div>
                <span>ì¤€ë¹„ ì¤‘...</span>
              </>
            )}
          </div>
          <button className="mic-stop-btn" onClick={handleMicMode}>ì¢…ë£Œ</button>
        </div>
      )}

      {isRecordingConsult && (
        <div className="recording-banner">
          <div className="rec-indicator">
            <div className="rec-dot"></div>
            <span>ìƒë‹´ ë…¹ìŒ ì¤‘...</span>
          </div>
          <button className="rec-stop-btn" onClick={handleRecordConsult}>ë…¹ìŒ ì¢…ë£Œ</button>
        </div>
      )}

      <div className="chat-area" ref={chatAreaRef}>
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.role}`}>
            {msg.files && (
              <div className="message-files">
                {msg.files.map((file, i) => (
                  <div key={i} className="file-preview-msg">
                    {file.preview ? (
                      <img src={file.preview} alt={file.name} />
                    ) : (
                      <span className="file-icon">ğŸ“„</span>
                    )}
                  </div>
                ))}
              </div>
            )}
            <div className="message-bubble">
              {msg.content.split('\n').map((line, i) => (
                <p key={i}>{line}</p>
              ))}
            </div>
            {msg.role === 'assistant' && msg.canDownload && (
              <div className="message-actions">
                <button className="action-btn" onClick={() => handleDownloadFile(msg.content)}>
                  ğŸ“„ ì €ì¥
                </button>
              </div>
            )}
            <div className="message-time">
              {msg.timestamp.toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })}
            </div>
          </div>
        ))}
        
        {currentTranscript && (
          <div className="message user interim">
            <div className="message-bubble">
              <p>{currentTranscript}</p>
            </div>
          </div>
        )}
        
        {loading && (
          <div className="message assistant">
            <div className="typing-indicator">
              <span></span><span></span><span></span>
            </div>
          </div>
        )}
      </div>

      <div className="input-area">
        {uploadedFiles.length > 0 && (
          <div className="uploaded-files">
            {uploadedFiles.map((file, index) => (
              <div key={index} className="uploaded-file">
                {file.preview ? (
                  <img src={file.preview} alt={file.name} />
                ) : (
                  <span className="file-icon">ğŸ“„</span>
                )}
                <button className="remove-file" onClick={() => removeFile(index)}>Ã—</button>
              </div>
            ))}
          </div>
        )}

        <div className="input-tools">
          <button className="tool-btn" onClick={handleCamera} title="ì¹´ë©”ë¼">
            <span className="tool-icon">ğŸ“·</span>
            <span className="tool-label">ì´¬ì˜</span>
          </button>
          <button className="tool-btn" onClick={handleFileSelect} title="íŒŒì¼ ì²¨ë¶€">
            <span className="tool-icon">ğŸ“</span>
            <span className="tool-label">íŒŒì¼</span>
          </button>
          <button 
            className={`tool-btn ${isMicMode ? 'active recording' : ''}`} 
            onClick={handleMicMode}
            title="ë§ˆì´í¬ (í…ìŠ¤íŠ¸ ë‹µë³€)"
          >
            <span className="tool-icon">ğŸ¤</span>
            <span className="tool-label">ë§ˆì´í¬</span>
          </button>
          <button 
            className={`tool-btn ${isVoiceMode ? 'active' : ''}`} 
            onClick={handleVoiceMode}
            title="ë³´ì´ìŠ¤ (ìŒì„± ëŒ€í™”)"
          >
            <span className="tool-icon">ğŸ”Š</span>
            <span className="tool-label">ë³´ì´ìŠ¤</span>
          </button>
          <button 
            className={`tool-btn ${isRecordingConsult ? 'active recording' : ''}`} 
            onClick={handleRecordConsult}
            title="ìƒë‹´ ë…¹ìŒ"
          >
            <span className="tool-icon">âºï¸</span>
            <span className="tool-label">ë…¹ìŒ</span>
          </button>
        </div>

        <div className="text-input-row">
          <input
            type="text"
            className="text-input"
            placeholder={isVoiceMode ? "ë³´ì´ìŠ¤ ëª¨ë“œ ì¤‘..." : isMicMode ? "ë§ˆì´í¬ ëª¨ë“œ ì¤‘..." : "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
            value={inputText}
            onChange={(e) => setInputText(e.target.value)}
            onKeyPress={handleKeyPress}
            disabled={loading}
          />
          <button
            className="send-btn"
            onClick={handleTextSubmit}
            disabled={loading || (!inputText.trim() && uploadedFiles.length === 0)}
          >
            â¤
          </button>
        </div>

        <input
          ref={cameraInputRef}
          type="file"
          accept="image/*"
          capture="environment"
          style={{ display: 'none' }}
          onChange={(e) => handleFileChange(e, true)}
        />
        <input
          ref={fileInputRef}
          type="file"
          accept="image/*,.pdf,.doc,.docx"
          multiple
          style={{ display: 'none' }}
          onChange={(e) => handleFileChange(e, false)}
        />
      </div>
    </div>
  );
}

export default MagicBoxPage;
